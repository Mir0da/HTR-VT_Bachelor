2025-06-11 18:54:49,579 INFO {
    "alpha": 1.0,
    "attn_mask_ratio": 0.1,
    "blur_max_kernel": 5,
    "blur_max_sigma": 5,
    "blur_min_kernel": 3,
    "blur_min_sigma": 3,
    "cos_temp": 8,
    "data_path": "./data/german/lines/",
    "dila_ero_iter": 1,
    "dila_ero_max_kernel": 2,
    "dpi_max_factor": 1.5,
    "dpi_min_factor": 0.5,
    "elastic_distortion_max_alpha": 1,
    "elastic_distortion_max_kernel_size": 3,
    "elastic_distortion_max_magnitude": 20,
    "elastic_distortion_max_sigma": 10,
    "elastic_distortion_min_alpha": 0.5,
    "elastic_distortion_min_kernel_size": 3,
    "elastic_distortion_min_sigma": 1,
    "ema_decay": 0.9999,
    "eval_iter": 1000,
    "exp_name": "german",
    "img_size": [
        1024,
        64
    ],
    "jitter_brightness": 0.4,
    "jitter_contrast": 0.4,
    "jitter_hue": 0.2,
    "jitter_saturation": 0.4,
    "mask_ratio": 0.4,
    "max_lr": 0.001,
    "max_span_length": 8,
    "nb_cls": 106,
    "num_workers": 0,
    "out_dir": "./output",
    "patch_size": [
        4,
        16
    ],
    "perspective_high": 0.4,
    "perspective_low": 0.0,
    "print_iter": 100,
    "proba": 0.5,
    "proj": 8.0,
    "save_dir": "./output\\german",
    "seed": 123,
    "sharpen_max_alpha": 1,
    "sharpen_max_strength": 1,
    "sharpen_min_alpha": 0,
    "sharpen_min_strength": 0,
    "spacing": 0,
    "subcommand": "GERMAN",
    "test_data_list": "./data/german/test.ln",
    "total_iter": 100000,
    "train_bs": 64,
    "train_data_list": "./data/german/train.ln",
    "use_wandb": false,
    "val_bs": 8,
    "val_data_list": "./data/german/val.ln",
    "warm_up_iter": 1000,
    "weight_decay": 0.5,
    "zoom_max_h": 1,
    "zoom_max_w": 1,
    "zoom_min_h": 0.8,
    "zoom_min_w": 0.99
}
2025-06-11 18:54:49,782 INFO total_param is 53604394
2025-06-11 18:54:49,923 INFO Loading train loader...
2025-06-11 18:55:14,461 INFO Loading val loader...
2025-06-11 18:57:07,805 INFO Iter : 100 	 LR : 0.00010 	 training loss : 308.01638 	 
2025-06-11 18:58:57,870 INFO Iter : 200 	 LR : 0.00020 	 training loss : 151.56079 	 
2025-06-11 19:00:47,125 INFO Iter : 300 	 LR : 0.00030 	 training loss : 143.79577 	 
2025-06-11 19:02:37,939 INFO Iter : 400 	 LR : 0.00040 	 training loss : 117.14933 	 
2025-06-11 19:04:26,979 INFO Iter : 500 	 LR : 0.00050 	 training loss : 84.01659 	 
2025-06-11 19:06:17,027 INFO Iter : 600 	 LR : 0.00060 	 training loss : 78.60220 	 
2025-06-11 19:08:08,552 INFO Iter : 700 	 LR : 0.00070 	 training loss : 71.71467 	 
2025-06-11 19:09:56,672 INFO Iter : 800 	 LR : 0.00080 	 training loss : 65.99422 	 
2025-06-11 19:11:45,855 INFO Iter : 900 	 LR : 0.00090 	 training loss : 62.95717 	 
2025-06-11 19:13:36,918 INFO Iter : 1000 	 LR : 0.00100 	 training loss : 61.43073 	 
2025-06-11 19:14:04,997 INFO CER improved from 1000000.0000 to 0.0797!!!
2025-06-11 19:14:05,247 INFO WER improved from 1000000.0000 to 0.3269!!!
2025-06-11 19:14:05,513 INFO Val. loss : 16.985 	 CER : 0.0797 	 WER : 0.3269 	 
2025-06-11 19:17:26,917 INFO Iter : 1100 	 LR : 0.00100 	 training loss : 57.92804 	 
2025-06-11 19:19:17,811 INFO Iter : 1200 	 LR : 0.00100 	 training loss : 55.58552 	 
2025-06-11 19:21:06,649 INFO Iter : 1300 	 LR : 0.00100 	 training loss : 53.61923 	 
2025-06-11 19:22:55,099 INFO Iter : 1400 	 LR : 0.00100 	 training loss : 50.49335 	 
2025-06-11 19:24:44,302 INFO Iter : 1500 	 LR : 0.00100 	 training loss : 47.84744 	 
2025-06-11 19:26:36,484 INFO Iter : 1600 	 LR : 0.00100 	 training loss : 46.59455 	 
2025-06-11 19:28:23,821 INFO Iter : 1700 	 LR : 0.00100 	 training loss : 43.54454 	 
2025-06-11 19:30:13,492 INFO Iter : 1800 	 LR : 0.00100 	 training loss : 41.73340 	 
2025-06-11 19:32:06,312 INFO Iter : 1900 	 LR : 0.00100 	 training loss : 39.28824 	 
2025-06-11 19:33:54,495 INFO Iter : 2000 	 LR : 0.00100 	 training loss : 37.60950 	 
2025-06-11 19:34:19,081 INFO CER improved from 0.0797 to 0.0420!!!
2025-06-11 19:34:19,331 INFO WER improved from 0.3269 to 0.1902!!!
2025-06-11 19:34:19,597 INFO Val. loss : 8.563 	 CER : 0.0420 	 WER : 0.1902 	 
2025-06-11 19:37:34,935 INFO Iter : 2100 	 LR : 0.00100 	 training loss : 36.59188 	 
2025-06-11 19:39:23,280 INFO Iter : 2200 	 LR : 0.00100 	 training loss : 34.10231 	 
2025-06-11 19:41:11,639 INFO Iter : 2300 	 LR : 0.00100 	 training loss : 32.59212 	 
2025-06-11 19:43:02,846 INFO Iter : 2400 	 LR : 0.00100 	 training loss : 31.84170 	 
2025-06-11 19:44:51,847 INFO Iter : 2500 	 LR : 0.00100 	 training loss : 29.62581 	 
2025-06-11 19:46:39,733 INFO Iter : 2600 	 LR : 0.00100 	 training loss : 29.55588 	 
2025-06-11 19:48:29,491 INFO Iter : 2700 	 LR : 0.00100 	 training loss : 27.28994 	 
2025-06-11 19:50:20,558 INFO Iter : 2800 	 LR : 0.00100 	 training loss : 26.74310 	 
2025-06-11 19:52:08,650 INFO Iter : 2900 	 LR : 0.00100 	 training loss : 26.36869 	 
2025-06-11 19:53:57,045 INFO Iter : 3000 	 LR : 0.00100 	 training loss : 24.44958 	 
2025-06-11 19:54:20,851 INFO CER improved from 0.0420 to 0.0312!!!
2025-06-11 19:54:21,148 INFO WER improved from 0.1902 to 0.1483!!!
2025-06-11 19:54:21,461 INFO Val. loss : 6.454 	 CER : 0.0312 	 WER : 0.1483 	 
2025-06-11 19:57:36,319 INFO Iter : 3100 	 LR : 0.00100 	 training loss : 24.44243 	 
2025-06-11 19:59:27,047 INFO Iter : 3200 	 LR : 0.00100 	 training loss : 22.90526 	 
2025-06-11 20:01:16,352 INFO Iter : 3300 	 LR : 0.00100 	 training loss : 23.17120 	 
2025-06-11 20:03:04,984 INFO Iter : 3400 	 LR : 0.00100 	 training loss : 22.29554 	 
2025-06-11 20:04:52,197 INFO Iter : 3500 	 LR : 0.00100 	 training loss : 21.32902 	 
2025-06-11 20:06:44,437 INFO Iter : 3600 	 LR : 0.00100 	 training loss : 21.62148 	 
2025-06-11 20:08:34,003 INFO Iter : 3700 	 LR : 0.00100 	 training loss : 20.74998 	 
2025-06-11 20:10:21,440 INFO Iter : 3800 	 LR : 0.00100 	 training loss : 21.46492 	 
2025-06-11 20:12:11,854 INFO Iter : 3900 	 LR : 0.00100 	 training loss : 21.00017 	 
2025-06-11 20:14:03,127 INFO Iter : 4000 	 LR : 0.00100 	 training loss : 19.00986 	 
2025-06-11 20:14:25,056 INFO CER improved from 0.0312 to 0.0269!!!
2025-06-11 20:14:25,384 INFO WER improved from 0.1483 to 0.1290!!!
2025-06-11 20:14:25,634 INFO Val. loss : 5.702 	 CER : 0.0269 	 WER : 0.1290 	 
2025-06-11 20:17:38,273 INFO Iter : 4100 	 LR : 0.00100 	 training loss : 19.59614 	 
2025-06-11 20:19:28,861 INFO Iter : 4200 	 LR : 0.00100 	 training loss : 18.96199 	 
2025-06-11 20:21:17,254 INFO Iter : 4300 	 LR : 0.00100 	 training loss : 19.16288 	 
2025-06-11 20:23:06,499 INFO Iter : 4400 	 LR : 0.00100 	 training loss : 18.65707 	 
2025-06-11 20:24:56,329 INFO Iter : 4500 	 LR : 0.00099 	 training loss : 17.75929 	 
2025-06-11 20:26:46,335 INFO Iter : 4600 	 LR : 0.00099 	 training loss : 17.94253 	 
2025-06-11 20:28:34,950 INFO Iter : 4700 	 LR : 0.00099 	 training loss : 18.32512 	 
2025-06-11 20:30:24,338 INFO Iter : 4800 	 LR : 0.00099 	 training loss : 17.55488 	 
2025-06-11 20:32:15,220 INFO Iter : 4900 	 LR : 0.00099 	 training loss : 17.56831 	 
2025-06-11 20:34:02,747 INFO Iter : 5000 	 LR : 0.00099 	 training loss : 16.87876 	 
2025-06-11 20:34:26,778 INFO CER improved from 0.0269 to 0.0248!!!
2025-06-11 20:34:27,043 INFO WER improved from 0.1290 to 0.1202!!!
2025-06-11 20:34:27,372 INFO Val. loss : 5.337 	 CER : 0.0248 	 WER : 0.1202 	 
2025-06-11 20:37:45,239 INFO Iter : 5100 	 LR : 0.00099 	 training loss : 17.50754 	 
2025-06-11 20:39:32,444 INFO Iter : 5200 	 LR : 0.00099 	 training loss : 16.78571 	 
2025-06-11 20:41:21,980 INFO Iter : 5300 	 LR : 0.00099 	 training loss : 17.80111 	 
2025-06-11 20:43:13,314 INFO Iter : 5400 	 LR : 0.00099 	 training loss : 16.87734 	 
2025-06-11 20:45:02,271 INFO Iter : 5500 	 LR : 0.00099 	 training loss : 17.63956 	 
2025-06-11 20:46:50,333 INFO Iter : 5600 	 LR : 0.00099 	 training loss : 17.35946 	 
2025-06-11 20:48:39,919 INFO Iter : 5700 	 LR : 0.00099 	 training loss : 17.36320 	 
2025-06-11 20:50:31,327 INFO Iter : 5800 	 LR : 0.00099 	 training loss : 16.18662 	 
2025-06-11 20:52:19,302 INFO Iter : 5900 	 LR : 0.00099 	 training loss : 16.39141 	 
2025-06-11 20:54:09,688 INFO Iter : 6000 	 LR : 0.00099 	 training loss : 16.68859 	 
2025-06-11 20:54:31,864 INFO CER improved from 0.0248 to 0.0243!!!
2025-06-11 20:54:32,161 INFO WER improved from 0.1202 to 0.1167!!!
2025-06-11 20:54:32,473 INFO Val. loss : 5.186 	 CER : 0.0243 	 WER : 0.1167 	 
2025-06-11 20:57:44,676 INFO Iter : 6100 	 LR : 0.00099 	 training loss : 15.87650 	 
2025-06-11 20:59:33,278 INFO Iter : 6200 	 LR : 0.00099 	 training loss : 16.09315 	 
2025-06-11 21:01:23,839 INFO Iter : 6300 	 LR : 0.00099 	 training loss : 15.77642 	 
2025-06-11 21:03:12,348 INFO Iter : 6400 	 LR : 0.00099 	 training loss : 16.09385 	 
2025-06-11 21:05:00,467 INFO Iter : 6500 	 LR : 0.00099 	 training loss : 15.81623 	 
2025-06-11 21:06:50,988 INFO Iter : 6600 	 LR : 0.00099 	 training loss : 15.99779 	 
2025-06-11 21:08:40,738 INFO Iter : 6700 	 LR : 0.00099 	 training loss : 15.78260 	 
2025-06-11 21:10:31,153 INFO Iter : 6800 	 LR : 0.00099 	 training loss : 16.01872 	 
2025-06-11 21:12:21,160 INFO Iter : 6900 	 LR : 0.00099 	 training loss : 15.34828 	 
2025-06-11 21:14:12,448 INFO Iter : 7000 	 LR : 0.00099 	 training loss : 16.11587 	 
2025-06-11 21:14:34,512 INFO CER improved from 0.0243 to 0.0229!!!
2025-06-11 21:14:34,793 INFO WER improved from 0.1167 to 0.1107!!!
2025-06-11 21:14:35,059 INFO Val. loss : 5.021 	 CER : 0.0229 	 WER : 0.1107 	 
2025-06-11 21:17:52,612 INFO Iter : 7100 	 LR : 0.00099 	 training loss : 15.75666 	 
2025-06-11 21:19:43,812 INFO Iter : 7200 	 LR : 0.00099 	 training loss : 15.48547 	 
2025-06-11 21:21:31,562 INFO Iter : 7300 	 LR : 0.00099 	 training loss : 15.03363 	 
2025-06-11 21:23:20,315 INFO Iter : 7400 	 LR : 0.00099 	 training loss : 16.18743 	 
2025-06-11 21:25:12,956 INFO Iter : 7500 	 LR : 0.00099 	 training loss : 15.50579 	 
2025-06-11 21:27:01,511 INFO Iter : 7600 	 LR : 0.00099 	 training loss : 15.31312 	 
2025-06-11 21:28:50,639 INFO Iter : 7700 	 LR : 0.00099 	 training loss : 15.85504 	 
2025-06-11 21:30:39,785 INFO Iter : 7800 	 LR : 0.00098 	 training loss : 14.90183 	 
2025-06-11 21:32:28,768 INFO Iter : 7900 	 LR : 0.00098 	 training loss : 15.75852 	 
2025-06-11 21:34:16,308 INFO Iter : 8000 	 LR : 0.00098 	 training loss : 15.08020 	 
2025-06-11 21:34:38,359 INFO Val. loss : 5.003 	 CER : 0.0230 	 WER : 0.1111 	 
2025-06-11 21:36:33,345 INFO Iter : 8100 	 LR : 0.00098 	 training loss : 15.37827 	 
2025-06-11 21:38:22,703 INFO Iter : 8200 	 LR : 0.00098 	 training loss : 16.11785 	 
2025-06-11 21:40:10,617 INFO Iter : 8300 	 LR : 0.00098 	 training loss : 15.19139 	 
2025-06-11 21:42:00,479 INFO Iter : 8400 	 LR : 0.00098 	 training loss : 15.02022 	 
2025-06-11 21:43:51,294 INFO Iter : 8500 	 LR : 0.00098 	 training loss : 15.40062 	 
2025-06-11 21:45:39,062 INFO Iter : 8600 	 LR : 0.00098 	 training loss : 14.51690 	 
2025-06-11 21:47:29,593 INFO Iter : 8700 	 LR : 0.00098 	 training loss : 16.03054 	 
2025-06-11 21:49:19,817 INFO Iter : 8800 	 LR : 0.00098 	 training loss : 14.83004 	 
2025-06-11 21:51:08,171 INFO Iter : 8900 	 LR : 0.00098 	 training loss : 14.83229 	 
2025-06-11 21:52:54,410 INFO Iter : 9000 	 LR : 0.00098 	 training loss : 15.36350 	 
2025-06-11 21:53:15,412 INFO CER improved from 0.0229 to 0.0223!!!
2025-06-11 21:53:15,678 INFO WER improved from 0.1107 to 0.1063!!!
2025-06-11 21:53:15,959 INFO Val. loss : 4.870 	 CER : 0.0223 	 WER : 0.1063 	 
2025-06-11 21:56:33,274 INFO Iter : 9100 	 LR : 0.00098 	 training loss : 16.02118 	 
2025-06-11 21:58:20,094 INFO Iter : 9200 	 LR : 0.00098 	 training loss : 14.80572 	 
2025-06-11 22:00:09,404 INFO Iter : 9300 	 LR : 0.00098 	 training loss : 14.96463 	 
2025-06-11 22:01:58,999 INFO Iter : 9400 	 LR : 0.00098 	 training loss : 15.08678 	 
2025-06-11 22:03:47,097 INFO Iter : 9500 	 LR : 0.00098 	 training loss : 14.54690 	 
2025-06-11 22:05:35,292 INFO Iter : 9600 	 LR : 0.00098 	 training loss : 14.96944 	 
2025-06-11 22:07:27,987 INFO Iter : 9700 	 LR : 0.00098 	 training loss : 15.54384 	 
2025-06-11 22:09:13,787 INFO Iter : 9800 	 LR : 0.00098 	 training loss : 14.81867 	 
2025-06-11 22:11:02,756 INFO Iter : 9900 	 LR : 0.00098 	 training loss : 15.44121 	 
2025-06-11 22:12:52,666 INFO Iter : 10000 	 LR : 0.00098 	 training loss : 14.50557 	 
2025-06-11 22:13:14,631 INFO CER improved from 0.0223 to 0.0221!!!
2025-06-11 22:13:14,897 INFO WER improved from 0.1063 to 0.1046!!!
2025-06-11 22:13:15,162 INFO Val. loss : 4.856 	 CER : 0.0221 	 WER : 0.1046 	 
2025-06-11 22:17:29,818 INFO Iter : 10100 	 LR : 0.00097 	 training loss : 14.77366 	 
2025-06-11 22:19:19,083 INFO Iter : 10200 	 LR : 0.00097 	 training loss : 14.19922 	 
2025-06-11 22:21:09,558 INFO Iter : 10300 	 LR : 0.00097 	 training loss : 14.41001 	 
2025-06-11 22:22:58,441 INFO Iter : 10400 	 LR : 0.00097 	 training loss : 14.43678 	 
2025-06-11 22:24:50,195 INFO Iter : 10500 	 LR : 0.00097 	 training loss : 14.99753 	 
2025-06-11 22:26:40,493 INFO Iter : 10600 	 LR : 0.00097 	 training loss : 14.22134 	 
2025-06-11 22:28:30,302 INFO Iter : 10700 	 LR : 0.00097 	 training loss : 14.17060 	 
2025-06-11 22:30:20,961 INFO Iter : 10800 	 LR : 0.00097 	 training loss : 14.28816 	 
2025-06-11 22:32:11,266 INFO Iter : 10900 	 LR : 0.00097 	 training loss : 15.21896 	 
2025-06-11 22:33:57,467 INFO Iter : 11000 	 LR : 0.00097 	 training loss : 14.23698 	 
2025-06-11 22:34:19,807 INFO Val. loss : 4.817 	 CER : 0.0221 	 WER : 0.1074 	 
2025-06-11 22:36:10,993 INFO Iter : 11100 	 LR : 0.00097 	 training loss : 15.00121 	 
2025-06-11 22:38:00,848 INFO Iter : 11200 	 LR : 0.00097 	 training loss : 14.04215 	 
2025-06-11 22:39:50,043 INFO Iter : 11300 	 LR : 0.00097 	 training loss : 13.85643 	 
2025-06-11 22:41:39,438 INFO Iter : 11400 	 LR : 0.00097 	 training loss : 14.65343 	 
2025-06-11 22:43:30,703 INFO Iter : 11500 	 LR : 0.00097 	 training loss : 13.96551 	 
2025-06-11 22:45:19,676 INFO Iter : 11600 	 LR : 0.00097 	 training loss : 13.74998 	 
2025-06-11 22:47:08,077 INFO Iter : 11700 	 LR : 0.00097 	 training loss : 14.23222 	 
2025-06-11 22:48:59,704 INFO Iter : 11800 	 LR : 0.00097 	 training loss : 13.84110 	 
2025-06-11 22:50:50,510 INFO Iter : 11900 	 LR : 0.00096 	 training loss : 14.42927 	 
2025-06-11 22:52:38,899 INFO Iter : 12000 	 LR : 0.00096 	 training loss : 14.05406 	 
2025-06-11 22:52:59,447 INFO CER improved from 0.0221 to 0.0215!!!
2025-06-11 22:52:59,728 INFO Val. loss : 4.830 	 CER : 0.0215 	 WER : 0.1046 	 
2025-06-11 22:55:49,056 INFO Iter : 12100 	 LR : 0.00096 	 training loss : 13.29938 	 
2025-06-11 22:57:39,087 INFO Iter : 12200 	 LR : 0.00096 	 training loss : 14.59154 	 
2025-06-11 22:59:27,111 INFO Iter : 12300 	 LR : 0.00096 	 training loss : 14.19771 	 
2025-06-11 23:01:19,695 INFO Iter : 12400 	 LR : 0.00096 	 training loss : 14.66475 	 
2025-06-11 23:03:07,095 INFO Iter : 12500 	 LR : 0.00096 	 training loss : 14.76232 	 
2025-06-11 23:04:55,111 INFO Iter : 12600 	 LR : 0.00096 	 training loss : 14.57624 	 
2025-06-11 23:06:45,273 INFO Iter : 12700 	 LR : 0.00096 	 training loss : 14.14281 	 
2025-06-11 23:08:35,457 INFO Iter : 12800 	 LR : 0.00096 	 training loss : 14.48333 	 
2025-06-11 23:10:23,694 INFO Iter : 12900 	 LR : 0.00096 	 training loss : 14.41660 	 
2025-06-11 23:12:11,634 INFO Iter : 13000 	 LR : 0.00096 	 training loss : 13.65830 	 
2025-06-11 23:12:33,649 INFO CER improved from 0.0215 to 0.0213!!!
2025-06-11 23:12:34,009 INFO WER improved from 0.1046 to 0.1033!!!
2025-06-11 23:12:34,368 INFO Val. loss : 4.830 	 CER : 0.0213 	 WER : 0.1033 	 
2025-06-11 23:15:45,798 INFO Iter : 13100 	 LR : 0.00096 	 training loss : 13.93037 	 
2025-06-11 23:17:37,711 INFO Iter : 13200 	 LR : 0.00096 	 training loss : 13.94628 	 
2025-06-11 23:19:26,547 INFO Iter : 13300 	 LR : 0.00096 	 training loss : 13.33243 	 
2025-06-11 23:21:15,693 INFO Iter : 13400 	 LR : 0.00096 	 training loss : 13.16468 	 
2025-06-11 23:23:03,622 INFO Iter : 13500 	 LR : 0.00095 	 training loss : 13.35320 	 
2025-06-11 23:24:55,344 INFO Iter : 13600 	 LR : 0.00095 	 training loss : 13.47033 	 
2025-06-11 23:26:44,965 INFO Iter : 13700 	 LR : 0.00095 	 training loss : 13.39571 	 
2025-06-11 23:28:29,843 INFO Iter : 13800 	 LR : 0.00095 	 training loss : 13.33809 	 
2025-06-11 23:30:18,569 INFO Iter : 13900 	 LR : 0.00095 	 training loss : 14.00672 	 
2025-06-11 23:32:08,588 INFO Iter : 14000 	 LR : 0.00095 	 training loss : 13.30448 	 
2025-06-11 23:32:30,868 INFO CER improved from 0.0213 to 0.0212!!!
2025-06-11 23:32:31,149 INFO WER improved from 0.1033 to 0.1009!!!
2025-06-11 23:32:31,399 INFO Val. loss : 4.846 	 CER : 0.0212 	 WER : 0.1009 	 
2025-06-11 23:35:50,825 INFO Iter : 14100 	 LR : 0.00095 	 training loss : 12.50216 	 
2025-06-11 23:37:41,020 INFO Iter : 14200 	 LR : 0.00095 	 training loss : 13.84735 	 
2025-06-11 23:39:30,843 INFO Iter : 14300 	 LR : 0.00095 	 training loss : 13.90409 	 
2025-06-11 23:41:19,411 INFO Iter : 14400 	 LR : 0.00095 	 training loss : 13.97090 	 
2025-06-11 23:43:08,463 INFO Iter : 14500 	 LR : 0.00095 	 training loss : 13.93090 	 
2025-06-11 23:44:57,120 INFO Iter : 14600 	 LR : 0.00095 	 training loss : 13.46807 	 
2025-06-11 23:46:44,493 INFO Iter : 14700 	 LR : 0.00095 	 training loss : 13.59761 	 
2025-06-11 23:48:34,346 INFO Iter : 14800 	 LR : 0.00095 	 training loss : 13.04780 	 
2025-06-11 23:50:23,687 INFO Iter : 14900 	 LR : 0.00095 	 training loss : 13.16394 	 
2025-06-11 23:52:10,737 INFO Iter : 15000 	 LR : 0.00094 	 training loss : 13.92071 	 
2025-06-11 23:52:33,265 INFO CER improved from 0.0212 to 0.0207!!!
2025-06-11 23:52:33,531 INFO WER improved from 0.1009 to 0.0983!!!
2025-06-11 23:52:33,765 INFO Val. loss : 4.813 	 CER : 0.0207 	 WER : 0.0983 	 
2025-06-11 23:55:51,774 INFO Iter : 15100 	 LR : 0.00094 	 training loss : 13.06062 	 
2025-06-11 23:57:39,137 INFO Iter : 15200 	 LR : 0.00094 	 training loss : 14.04947 	 
2025-06-11 23:59:25,185 INFO Iter : 15300 	 LR : 0.00094 	 training loss : 12.86158 	 
2025-06-12 00:01:15,819 INFO Iter : 15400 	 LR : 0.00094 	 training loss : 13.39428 	 
2025-06-12 00:03:04,231 INFO Iter : 15500 	 LR : 0.00094 	 training loss : 13.40457 	 
2025-06-12 00:04:51,775 INFO Iter : 15600 	 LR : 0.00094 	 training loss : 13.07310 	 
2025-06-12 00:06:42,001 INFO Iter : 15700 	 LR : 0.00094 	 training loss : 13.19138 	 
2025-06-12 00:08:32,417 INFO Iter : 15800 	 LR : 0.00094 	 training loss : 13.05470 	 
2025-06-12 00:10:19,781 INFO Iter : 15900 	 LR : 0.00094 	 training loss : 13.16990 	 
2025-06-12 00:12:09,471 INFO Iter : 16000 	 LR : 0.00094 	 training loss : 13.27288 	 
2025-06-12 00:12:31,421 INFO CER improved from 0.0207 to 0.0201!!!
2025-06-12 00:12:31,687 INFO WER improved from 0.0983 to 0.0961!!!
2025-06-12 00:12:31,989 INFO Val. loss : 4.728 	 CER : 0.0201 	 WER : 0.0961 	 
2025-06-12 00:15:47,211 INFO Iter : 16100 	 LR : 0.00094 	 training loss : 13.30745 	 
2025-06-12 00:17:35,503 INFO Iter : 16200 	 LR : 0.00094 	 training loss : 13.57008 	 
2025-06-12 00:19:25,558 INFO Iter : 16300 	 LR : 0.00093 	 training loss : 13.68634 	 
2025-06-12 00:21:14,780 INFO Iter : 16400 	 LR : 0.00093 	 training loss : 13.18283 	 
2025-06-12 00:23:04,217 INFO Iter : 16500 	 LR : 0.00093 	 training loss : 13.30149 	 
2025-06-12 00:24:54,268 INFO Iter : 16600 	 LR : 0.00093 	 training loss : 13.00790 	 
2025-06-12 00:26:42,296 INFO Iter : 16700 	 LR : 0.00093 	 training loss : 12.39164 	 
2025-06-12 00:28:29,830 INFO Iter : 16800 	 LR : 0.00093 	 training loss : 12.73586 	 
2025-06-12 00:30:20,179 INFO Iter : 16900 	 LR : 0.00093 	 training loss : 12.46972 	 
2025-06-12 00:32:13,514 INFO Iter : 17000 	 LR : 0.00093 	 training loss : 12.73035 	 
2025-06-12 00:32:35,099 INFO Val. loss : 4.706 	 CER : 0.0204 	 WER : 0.0977 	 
2025-06-12 00:34:28,322 INFO Iter : 17100 	 LR : 0.00093 	 training loss : 13.28536 	 
2025-06-12 00:36:17,038 INFO Iter : 17200 	 LR : 0.00093 	 training loss : 13.32044 	 
2025-06-12 00:38:06,027 INFO Iter : 17300 	 LR : 0.00093 	 training loss : 12.04610 	 
2025-06-12 00:39:56,511 INFO Iter : 17400 	 LR : 0.00093 	 training loss : 12.98747 	 
2025-06-12 00:41:44,582 INFO Iter : 17500 	 LR : 0.00092 	 training loss : 12.25623 	 
2025-06-12 00:43:35,182 INFO Iter : 17600 	 LR : 0.00092 	 training loss : 12.71230 	 
2025-06-12 00:45:23,914 INFO Iter : 17700 	 LR : 0.00092 	 training loss : 12.99662 	 
2025-06-12 00:47:12,482 INFO Iter : 17800 	 LR : 0.00092 	 training loss : 12.36684 	 
2025-06-12 00:49:02,649 INFO Iter : 17900 	 LR : 0.00092 	 training loss : 13.53457 	 
2025-06-12 00:50:52,707 INFO Iter : 18000 	 LR : 0.00092 	 training loss : 12.72243 	 
2025-06-12 00:51:13,152 INFO CER improved from 0.0201 to 0.0200!!!
2025-06-12 00:51:13,449 INFO WER improved from 0.0961 to 0.0947!!!
2025-06-12 00:51:13,731 INFO Val. loss : 4.654 	 CER : 0.0200 	 WER : 0.0947 	 
2025-06-12 00:54:32,030 INFO Iter : 18100 	 LR : 0.00092 	 training loss : 13.27492 	 
2025-06-12 00:56:21,438 INFO Iter : 18200 	 LR : 0.00092 	 training loss : 13.04111 	 
2025-06-12 00:58:09,127 INFO Iter : 18300 	 LR : 0.00092 	 training loss : 12.05073 	 
2025-06-12 00:59:58,932 INFO Iter : 18400 	 LR : 0.00092 	 training loss : 13.42182 	 
2025-06-12 01:01:49,423 INFO Iter : 18500 	 LR : 0.00092 	 training loss : 12.97216 	 
2025-06-12 01:03:39,032 INFO Iter : 18600 	 LR : 0.00092 	 training loss : 11.92354 	 
2025-06-12 01:05:25,700 INFO Iter : 18700 	 LR : 0.00091 	 training loss : 12.59041 	 
2025-06-12 01:07:16,893 INFO Iter : 18800 	 LR : 0.00091 	 training loss : 13.11673 	 
2025-06-12 01:09:03,861 INFO Iter : 18900 	 LR : 0.00091 	 training loss : 13.21828 	 
2025-06-12 01:10:51,079 INFO Iter : 19000 	 LR : 0.00091 	 training loss : 11.81949 	 
2025-06-12 01:11:15,472 INFO CER improved from 0.0200 to 0.0199!!!
2025-06-12 01:11:15,800 INFO Val. loss : 4.679 	 CER : 0.0199 	 WER : 0.0955 	 
2025-06-12 01:14:02,252 INFO Iter : 19100 	 LR : 0.00091 	 training loss : 12.38561 	 
2025-06-12 01:15:50,713 INFO Iter : 19200 	 LR : 0.00091 	 training loss : 12.19408 	 
2025-06-12 01:17:41,757 INFO Iter : 19300 	 LR : 0.00091 	 training loss : 12.28808 	 
2025-06-12 01:19:32,407 INFO Iter : 19400 	 LR : 0.00091 	 training loss : 13.61488 	 
2025-06-12 01:21:19,665 INFO Iter : 19500 	 LR : 0.00091 	 training loss : 11.86496 	 
2025-06-12 01:23:06,935 INFO Iter : 19600 	 LR : 0.00091 	 training loss : 12.30062 	 
2025-06-12 01:24:58,265 INFO Iter : 19700 	 LR : 0.00091 	 training loss : 13.54944 	 
2025-06-12 01:26:48,179 INFO Iter : 19800 	 LR : 0.00090 	 training loss : 12.98514 	 
2025-06-12 01:28:36,014 INFO Iter : 19900 	 LR : 0.00090 	 training loss : 12.71179 	 
2025-06-12 01:30:26,231 INFO Iter : 20000 	 LR : 0.00090 	 training loss : 12.84059 	 
2025-06-12 01:30:47,799 INFO CER improved from 0.0199 to 0.0196!!!
2025-06-12 01:30:48,160 INFO WER improved from 0.0947 to 0.0935!!!
2025-06-12 01:30:48,473 INFO Val. loss : 4.683 	 CER : 0.0196 	 WER : 0.0935 	 
2025-06-12 01:34:06,660 INFO Iter : 20100 	 LR : 0.00090 	 training loss : 12.09942 	 
2025-06-12 01:35:54,871 INFO Iter : 20200 	 LR : 0.00090 	 training loss : 12.92381 	 
2025-06-12 01:37:43,903 INFO Iter : 20300 	 LR : 0.00090 	 training loss : 12.16965 	 
2025-06-12 01:39:31,639 INFO Iter : 20400 	 LR : 0.00090 	 training loss : 12.21330 	 
2025-06-12 01:41:20,700 INFO Iter : 20500 	 LR : 0.00090 	 training loss : 12.95511 	 
2025-06-12 01:43:11,204 INFO Iter : 20600 	 LR : 0.00090 	 training loss : 12.16325 	 
2025-06-12 01:44:58,518 INFO Iter : 20700 	 LR : 0.00090 	 training loss : 12.48511 	 
2025-06-12 01:46:46,940 INFO Iter : 20800 	 LR : 0.00089 	 training loss : 12.50792 	 
2025-06-12 01:48:37,062 INFO Iter : 20900 	 LR : 0.00089 	 training loss : 12.43111 	 
2025-06-12 01:50:27,183 INFO Iter : 21000 	 LR : 0.00089 	 training loss : 12.32355 	 
2025-06-12 01:50:49,576 INFO CER improved from 0.0196 to 0.0195!!!
2025-06-12 01:50:49,841 INFO WER improved from 0.0935 to 0.0926!!!
2025-06-12 01:50:50,107 INFO Val. loss : 4.613 	 CER : 0.0195 	 WER : 0.0926 	 
2025-06-12 01:54:06,481 INFO Iter : 21100 	 LR : 0.00089 	 training loss : 12.01139 	 
2025-06-12 01:55:57,520 INFO Iter : 21200 	 LR : 0.00089 	 training loss : 11.45957 	 
2025-06-12 01:57:46,258 INFO Iter : 21300 	 LR : 0.00089 	 training loss : 12.75356 	 
2025-06-12 01:59:34,104 INFO Iter : 21400 	 LR : 0.00089 	 training loss : 12.55988 	 
2025-06-12 02:01:23,499 INFO Iter : 21500 	 LR : 0.00089 	 training loss : 12.78186 	 
2025-06-12 02:03:11,842 INFO Iter : 21600 	 LR : 0.00089 	 training loss : 12.19808 	 
2025-06-12 02:04:59,225 INFO Iter : 21700 	 LR : 0.00089 	 training loss : 12.15250 	 
2025-06-12 02:06:49,711 INFO Iter : 21800 	 LR : 0.00089 	 training loss : 12.69237 	 
2025-06-12 02:08:37,692 INFO Iter : 21900 	 LR : 0.00088 	 training loss : 11.55613 	 
2025-06-12 02:10:25,954 INFO Iter : 22000 	 LR : 0.00088 	 training loss : 13.00416 	 
2025-06-12 02:10:47,613 INFO Val. loss : 4.628 	 CER : 0.0198 	 WER : 0.0942 	 
2025-06-12 02:12:41,656 INFO Iter : 22100 	 LR : 0.00088 	 training loss : 11.64928 	 
2025-06-12 02:14:30,768 INFO Iter : 22200 	 LR : 0.00088 	 training loss : 12.28943 	 
2025-06-12 02:16:19,399 INFO Iter : 22300 	 LR : 0.00088 	 training loss : 12.66975 	 
2025-06-12 02:18:07,499 INFO Iter : 22400 	 LR : 0.00088 	 training loss : 12.69267 	 
2025-06-12 02:19:59,848 INFO Iter : 22500 	 LR : 0.00088 	 training loss : 11.80590 	 
2025-06-12 02:21:47,357 INFO Iter : 22600 	 LR : 0.00088 	 training loss : 11.99559 	 
2025-06-12 02:23:36,179 INFO Iter : 22700 	 LR : 0.00088 	 training loss : 12.22857 	 
2025-06-12 02:25:26,771 INFO Iter : 22800 	 LR : 0.00087 	 training loss : 12.34044 	 
2025-06-12 02:27:15,399 INFO Iter : 22900 	 LR : 0.00087 	 training loss : 11.97845 	 
2025-06-12 02:29:03,327 INFO Iter : 23000 	 LR : 0.00087 	 training loss : 12.58687 	 
2025-06-12 02:29:24,475 INFO Val. loss : 4.637 	 CER : 0.0198 	 WER : 0.0946 	 
2025-06-12 02:31:19,826 INFO Iter : 23100 	 LR : 0.00087 	 training loss : 12.56357 	 
2025-06-12 02:33:08,474 INFO Iter : 23200 	 LR : 0.00087 	 training loss : 11.80005 	 
2025-06-12 02:34:55,931 INFO Iter : 23300 	 LR : 0.00087 	 training loss : 12.34995 	 
2025-06-12 02:36:46,081 INFO Iter : 23400 	 LR : 0.00087 	 training loss : 12.47093 	 
2025-06-12 02:38:35,496 INFO Iter : 23500 	 LR : 0.00087 	 training loss : 12.01916 	 
2025-06-12 02:40:23,249 INFO Iter : 23600 	 LR : 0.00087 	 training loss : 12.05230 	 
2025-06-12 02:42:12,800 INFO Iter : 23700 	 LR : 0.00087 	 training loss : 12.36828 	 
2025-06-12 02:44:02,420 INFO Iter : 23800 	 LR : 0.00086 	 training loss : 11.25780 	 
2025-06-12 02:45:51,434 INFO Iter : 23900 	 LR : 0.00086 	 training loss : 11.82822 	 
2025-06-12 02:47:41,075 INFO Iter : 24000 	 LR : 0.00086 	 training loss : 11.64528 	 
2025-06-12 02:48:03,403 INFO Val. loss : 4.634 	 CER : 0.0198 	 WER : 0.0938 	 
2025-06-12 02:49:59,485 INFO Iter : 24100 	 LR : 0.00086 	 training loss : 11.81758 	 
2025-06-12 02:51:46,370 INFO Iter : 24200 	 LR : 0.00086 	 training loss : 12.01984 	 
2025-06-12 02:53:35,137 INFO Iter : 24300 	 LR : 0.00086 	 training loss : 11.72925 	 
2025-06-12 02:55:24,782 INFO Iter : 24400 	 LR : 0.00086 	 training loss : 11.22787 	 
2025-06-12 02:57:14,760 INFO Iter : 24500 	 LR : 0.00086 	 training loss : 12.34996 	 
2025-06-12 02:59:03,950 INFO Iter : 24600 	 LR : 0.00086 	 training loss : 11.92082 	 
2025-06-12 03:00:53,773 INFO Iter : 24700 	 LR : 0.00085 	 training loss : 12.14634 	 
2025-06-12 03:02:41,899 INFO Iter : 24800 	 LR : 0.00085 	 training loss : 11.52952 	 
2025-06-12 03:04:30,108 INFO Iter : 24900 	 LR : 0.00085 	 training loss : 10.87067 	 
2025-06-12 03:06:20,879 INFO Iter : 25000 	 LR : 0.00085 	 training loss : 12.24338 	 
2025-06-12 03:06:42,577 INFO Val. loss : 4.649 	 CER : 0.0198 	 WER : 0.0942 	 
2025-06-12 03:08:38,132 INFO Iter : 25100 	 LR : 0.00085 	 training loss : 11.57576 	 
2025-06-12 03:10:25,528 INFO Iter : 25200 	 LR : 0.00085 	 training loss : 11.34857 	 
2025-06-12 03:12:15,562 INFO Iter : 25300 	 LR : 0.00085 	 training loss : 11.83864 	 
2025-06-12 03:14:04,264 INFO Iter : 25400 	 LR : 0.00085 	 training loss : 12.15413 	 
2025-06-12 03:15:51,361 INFO Iter : 25500 	 LR : 0.00085 	 training loss : 12.64859 	 
2025-06-12 03:17:41,668 INFO Iter : 25600 	 LR : 0.00084 	 training loss : 11.39508 	 
2025-06-12 03:19:31,771 INFO Iter : 25700 	 LR : 0.00084 	 training loss : 12.33358 	 
2025-06-12 03:21:19,862 INFO Iter : 25800 	 LR : 0.00084 	 training loss : 11.06971 	 
2025-06-12 03:23:09,202 INFO Iter : 25900 	 LR : 0.00084 	 training loss : 12.24346 	 
2025-06-12 03:24:57,560 INFO Iter : 26000 	 LR : 0.00084 	 training loss : 11.58280 	 
2025-06-12 03:25:18,375 INFO Val. loss : 4.602 	 CER : 0.0197 	 WER : 0.0935 	 
2025-06-12 03:27:14,377 INFO Iter : 26100 	 LR : 0.00084 	 training loss : 11.65963 	 
2025-06-12 03:29:02,130 INFO Iter : 26200 	 LR : 0.00084 	 training loss : 12.11050 	 
2025-06-12 03:30:52,376 INFO Iter : 26300 	 LR : 0.00084 	 training loss : 11.84813 	 
2025-06-12 03:32:41,093 INFO Iter : 26400 	 LR : 0.00083 	 training loss : 11.42014 	 
2025-06-12 03:34:28,405 INFO Iter : 26500 	 LR : 0.00083 	 training loss : 12.39479 	 
2025-06-12 03:36:15,535 INFO Iter : 26600 	 LR : 0.00083 	 training loss : 10.88578 	 
2025-06-12 03:38:06,414 INFO Iter : 26700 	 LR : 0.00083 	 training loss : 12.87671 	 
2025-06-12 03:39:55,452 INFO Iter : 26800 	 LR : 0.00083 	 training loss : 11.53228 	 
2025-06-12 03:41:43,446 INFO Iter : 26900 	 LR : 0.00083 	 training loss : 11.64261 	 
2025-06-12 03:43:35,526 INFO Iter : 27000 	 LR : 0.00083 	 training loss : 12.19340 	 
2025-06-12 03:43:56,131 INFO Val. loss : 4.596 	 CER : 0.0196 	 WER : 0.0929 	 
2025-06-12 03:45:48,715 INFO Iter : 27100 	 LR : 0.00083 	 training loss : 11.18342 	 
2025-06-12 03:47:35,796 INFO Iter : 27200 	 LR : 0.00083 	 training loss : 10.44046 	 
2025-06-12 03:49:26,835 INFO Iter : 27300 	 LR : 0.00082 	 training loss : 10.81107 	 
2025-06-12 03:51:15,442 INFO Iter : 27400 	 LR : 0.00082 	 training loss : 12.21372 	 
2025-06-12 03:53:03,683 INFO Iter : 27500 	 LR : 0.00082 	 training loss : 11.45437 	 
2025-06-12 03:54:53,634 INFO Iter : 27600 	 LR : 0.00082 	 training loss : 11.44202 	 
2025-06-12 03:56:44,231 INFO Iter : 27700 	 LR : 0.00082 	 training loss : 10.89056 	 
2025-06-12 03:58:32,537 INFO Iter : 27800 	 LR : 0.00082 	 training loss : 12.16492 	 
2025-06-12 04:00:22,693 INFO Iter : 27900 	 LR : 0.00082 	 training loss : 12.49565 	 
2025-06-12 04:02:14,395 INFO Iter : 28000 	 LR : 0.00082 	 training loss : 12.35587 	 
2025-06-12 04:02:36,470 INFO CER improved from 0.0195 to 0.0195!!!
2025-06-12 04:02:36,704 INFO Val. loss : 4.549 	 CER : 0.0195 	 WER : 0.0945 	 
2025-06-12 04:05:21,557 INFO Iter : 28100 	 LR : 0.00081 	 training loss : 11.59700 	 
2025-06-12 04:07:11,380 INFO Iter : 28200 	 LR : 0.00081 	 training loss : 11.51047 	 
2025-06-12 04:08:59,205 INFO Iter : 28300 	 LR : 0.00081 	 training loss : 11.17754 	 
2025-06-12 04:10:48,602 INFO Iter : 28400 	 LR : 0.00081 	 training loss : 11.34809 	 
2025-06-12 04:12:38,150 INFO Iter : 28500 	 LR : 0.00081 	 training loss : 12.48646 	 
2025-06-12 04:14:30,605 INFO Iter : 28600 	 LR : 0.00081 	 training loss : 10.90796 	 
2025-06-12 04:16:16,683 INFO Iter : 28700 	 LR : 0.00081 	 training loss : 11.63020 	 
2025-06-12 04:18:06,723 INFO Iter : 28800 	 LR : 0.00081 	 training loss : 11.12374 	 
2025-06-12 04:19:57,798 INFO Iter : 28900 	 LR : 0.00080 	 training loss : 11.46279 	 
2025-06-12 04:21:45,888 INFO Iter : 29000 	 LR : 0.00080 	 training loss : 12.04996 	 
2025-06-12 04:22:07,840 INFO CER improved from 0.0195 to 0.0191!!!
2025-06-12 04:22:08,153 INFO WER improved from 0.0926 to 0.0910!!!
2025-06-12 04:22:08,418 INFO Val. loss : 4.548 	 CER : 0.0191 	 WER : 0.0910 	 
2025-06-12 04:25:28,932 INFO Iter : 29100 	 LR : 0.00080 	 training loss : 10.77566 	 
2025-06-12 04:27:17,771 INFO Iter : 29200 	 LR : 0.00080 	 training loss : 10.97352 	 
2025-06-12 04:29:06,953 INFO Iter : 29300 	 LR : 0.00080 	 training loss : 11.64371 	 
2025-06-12 04:30:58,181 INFO Iter : 29400 	 LR : 0.00080 	 training loss : 11.64126 	 
2025-06-12 04:32:48,316 INFO Iter : 29500 	 LR : 0.00080 	 training loss : 11.78470 	 
2025-06-12 04:34:35,731 INFO Iter : 29600 	 LR : 0.00080 	 training loss : 10.94972 	 
2025-06-12 04:36:25,862 INFO Iter : 29700 	 LR : 0.00079 	 training loss : 10.78823 	 
2025-06-12 04:38:14,387 INFO Iter : 29800 	 LR : 0.00079 	 training loss : 11.28209 	 
2025-06-12 04:40:02,417 INFO Iter : 29900 	 LR : 0.00079 	 training loss : 11.71236 	 
2025-06-12 04:41:52,181 INFO Iter : 30000 	 LR : 0.00079 	 training loss : 10.63070 	 
2025-06-12 04:42:14,631 INFO CER improved from 0.0191 to 0.0190!!!
2025-06-12 04:42:14,898 INFO Val. loss : 4.501 	 CER : 0.0190 	 WER : 0.0911 	 
2025-06-12 04:44:57,951 INFO Iter : 30100 	 LR : 0.00079 	 training loss : 11.32684 	 
2025-06-12 04:46:46,617 INFO Iter : 30200 	 LR : 0.00079 	 training loss : 11.45791 	 
2025-06-12 04:48:37,749 INFO Iter : 30300 	 LR : 0.00079 	 training loss : 11.71667 	 
2025-06-12 04:50:28,035 INFO Iter : 30400 	 LR : 0.00078 	 training loss : 10.82701 	 
2025-06-12 04:52:16,154 INFO Iter : 30500 	 LR : 0.00078 	 training loss : 11.11854 	 
2025-06-12 04:54:05,540 INFO Iter : 30600 	 LR : 0.00078 	 training loss : 10.92138 	 
2025-06-12 04:55:58,464 INFO Iter : 30700 	 LR : 0.00078 	 training loss : 11.03782 	 
2025-06-12 04:57:46,818 INFO Iter : 30800 	 LR : 0.00078 	 training loss : 10.27119 	 
2025-06-12 04:59:36,516 INFO Iter : 30900 	 LR : 0.00078 	 training loss : 12.02293 	 
2025-06-12 05:01:27,274 INFO Iter : 31000 	 LR : 0.00078 	 training loss : 11.60479 	 
2025-06-12 05:01:47,878 INFO CER improved from 0.0190 to 0.0189!!!
2025-06-12 05:01:48,191 INFO WER improved from 0.0910 to 0.0906!!!
2025-06-12 05:01:48,472 INFO Val. loss : 4.497 	 CER : 0.0189 	 WER : 0.0906 	 
2025-06-12 05:05:06,209 INFO Iter : 31100 	 LR : 0.00078 	 training loss : 10.54459 	 
2025-06-12 05:06:54,672 INFO Iter : 31200 	 LR : 0.00077 	 training loss : 11.43849 	 
2025-06-12 05:08:44,636 INFO Iter : 31300 	 LR : 0.00077 	 training loss : 11.78522 	 
2025-06-12 05:10:33,213 INFO Iter : 31400 	 LR : 0.00077 	 training loss : 11.78520 	 
2025-06-12 05:12:24,274 INFO Iter : 31500 	 LR : 0.00077 	 training loss : 11.60877 	 
2025-06-12 05:14:14,529 INFO Iter : 31600 	 LR : 0.00077 	 training loss : 10.78573 	 
2025-06-12 05:16:02,312 INFO Iter : 31700 	 LR : 0.00077 	 training loss : 11.28713 	 
2025-06-12 05:17:51,452 INFO Iter : 31800 	 LR : 0.00077 	 training loss : 10.42251 	 
2025-06-12 05:19:43,615 INFO Iter : 31900 	 LR : 0.00076 	 training loss : 11.48641 	 
2025-06-12 05:21:31,863 INFO Iter : 32000 	 LR : 0.00076 	 training loss : 11.80722 	 
2025-06-12 05:21:54,267 INFO CER improved from 0.0189 to 0.0186!!!
2025-06-12 05:21:54,517 INFO WER improved from 0.0906 to 0.0882!!!
2025-06-12 05:21:54,783 INFO Val. loss : 4.454 	 CER : 0.0186 	 WER : 0.0882 	 
2025-06-12 05:25:14,396 INFO Iter : 32100 	 LR : 0.00076 	 training loss : 11.42415 	 
2025-06-12 05:27:02,226 INFO Iter : 32200 	 LR : 0.00076 	 training loss : 10.78549 	 
2025-06-12 05:28:50,906 INFO Iter : 32300 	 LR : 0.00076 	 training loss : 10.46419 	 
2025-06-12 05:30:38,641 INFO Iter : 32400 	 LR : 0.00076 	 training loss : 10.38582 	 
2025-06-12 05:32:28,300 INFO Iter : 32500 	 LR : 0.00076 	 training loss : 10.96860 	 
2025-06-12 05:34:14,935 INFO Iter : 32600 	 LR : 0.00076 	 training loss : 11.12528 	 
2025-06-12 05:36:03,849 INFO Iter : 32700 	 LR : 0.00075 	 training loss : 10.58044 	 
2025-06-12 05:37:52,820 INFO Iter : 32800 	 LR : 0.00075 	 training loss : 10.11555 	 
2025-06-12 05:39:40,590 INFO Iter : 32900 	 LR : 0.00075 	 training loss : 11.41897 	 
2025-06-12 05:41:29,895 INFO Iter : 33000 	 LR : 0.00075 	 training loss : 11.05674 	 
2025-06-12 05:41:54,709 INFO CER improved from 0.0186 to 0.0184!!!
2025-06-12 05:41:54,975 INFO WER improved from 0.0882 to 0.0877!!!
2025-06-12 05:41:55,256 INFO Val. loss : 4.424 	 CER : 0.0184 	 WER : 0.0877 	 
2025-06-12 05:45:14,397 INFO Iter : 33100 	 LR : 0.00075 	 training loss : 10.50298 	 
2025-06-12 05:47:01,694 INFO Iter : 33200 	 LR : 0.00075 	 training loss : 10.61023 	 
2025-06-12 05:48:51,132 INFO Iter : 33300 	 LR : 0.00075 	 training loss : 11.59453 	 
2025-06-12 05:50:40,566 INFO Iter : 33400 	 LR : 0.00074 	 training loss : 11.65434 	 
2025-06-12 05:52:27,363 INFO Iter : 33500 	 LR : 0.00074 	 training loss : 11.31824 	 
2025-06-12 05:54:15,370 INFO Iter : 33600 	 LR : 0.00074 	 training loss : 10.25297 	 
2025-06-12 05:56:04,857 INFO Iter : 33700 	 LR : 0.00074 	 training loss : 10.35272 	 
2025-06-12 05:57:50,953 INFO Iter : 33800 	 LR : 0.00074 	 training loss : 11.11078 	 
2025-06-12 05:59:40,129 INFO Iter : 33900 	 LR : 0.00074 	 training loss : 10.65864 	 
2025-06-12 06:01:29,939 INFO Iter : 34000 	 LR : 0.00074 	 training loss : 10.44687 	 
2025-06-12 06:01:50,282 INFO CER improved from 0.0184 to 0.0179!!!
2025-06-12 06:01:50,563 INFO WER improved from 0.0877 to 0.0857!!!
2025-06-12 06:01:50,828 INFO Val. loss : 4.349 	 CER : 0.0179 	 WER : 0.0857 	 
2025-06-12 06:05:08,666 INFO Iter : 34100 	 LR : 0.00073 	 training loss : 11.32995 	 
2025-06-12 06:06:57,299 INFO Iter : 34200 	 LR : 0.00073 	 training loss : 11.65956 	 
2025-06-12 06:08:44,582 INFO Iter : 34300 	 LR : 0.00073 	 training loss : 9.58223 	 
2025-06-12 06:10:33,441 INFO Iter : 34400 	 LR : 0.00073 	 training loss : 10.40278 	 
2025-06-12 06:12:23,485 INFO Iter : 34500 	 LR : 0.00073 	 training loss : 11.45923 	 
2025-06-12 06:14:15,263 INFO Iter : 34600 	 LR : 0.00073 	 training loss : 11.52121 	 
2025-06-12 06:16:03,319 INFO Iter : 34700 	 LR : 0.00073 	 training loss : 11.34598 	 
2025-06-12 06:17:53,034 INFO Iter : 34800 	 LR : 0.00072 	 training loss : 10.62887 	 
2025-06-12 06:19:42,939 INFO Iter : 34900 	 LR : 0.00072 	 training loss : 11.07513 	 
2025-06-12 06:21:31,879 INFO Iter : 35000 	 LR : 0.00072 	 training loss : 10.46260 	 
2025-06-12 06:21:53,500 INFO Val. loss : 4.397 	 CER : 0.0184 	 WER : 0.0887 	 
2025-06-12 06:23:46,923 INFO Iter : 35100 	 LR : 0.00072 	 training loss : 11.04674 	 
2025-06-12 06:25:36,647 INFO Iter : 35200 	 LR : 0.00072 	 training loss : 10.37520 	 
2025-06-12 06:27:24,965 INFO Iter : 35300 	 LR : 0.00072 	 training loss : 9.87017 	 
2025-06-12 06:29:13,723 INFO Iter : 35400 	 LR : 0.00072 	 training loss : 10.69042 	 
2025-06-12 06:31:02,154 INFO Iter : 35500 	 LR : 0.00071 	 training loss : 10.75086 	 
2025-06-12 06:32:50,760 INFO Iter : 35600 	 LR : 0.00071 	 training loss : 10.41091 	 
2025-06-12 06:34:36,279 INFO Iter : 35700 	 LR : 0.00071 	 training loss : 10.64846 	 
2025-06-12 06:36:27,399 INFO Iter : 35800 	 LR : 0.00071 	 training loss : 10.37257 	 
2025-06-12 06:38:17,677 INFO Iter : 35900 	 LR : 0.00071 	 training loss : 10.58351 	 
2025-06-12 06:40:04,632 INFO Iter : 36000 	 LR : 0.00071 	 training loss : 9.76725 	 
2025-06-12 06:40:26,417 INFO Val. loss : 4.404 	 CER : 0.0184 	 WER : 0.0891 	 
2025-06-12 06:42:22,022 INFO Iter : 36100 	 LR : 0.00071 	 training loss : 11.22828 	 
2025-06-12 06:44:11,512 INFO Iter : 36200 	 LR : 0.00070 	 training loss : 10.20659 	 
2025-06-12 06:45:58,329 INFO Iter : 36300 	 LR : 0.00070 	 training loss : 10.19030 	 
2025-06-12 06:47:49,000 INFO Iter : 36400 	 LR : 0.00070 	 training loss : 10.29325 	 
2025-06-12 06:49:39,596 INFO Iter : 36500 	 LR : 0.00070 	 training loss : 10.37334 	 
2025-06-12 06:51:27,033 INFO Iter : 36600 	 LR : 0.00070 	 training loss : 9.78859 	 
2025-06-12 06:53:15,455 INFO Iter : 36700 	 LR : 0.00070 	 training loss : 10.07326 	 
2025-06-12 06:55:05,485 INFO Iter : 36800 	 LR : 0.00070 	 training loss : 10.24104 	 
2025-06-12 06:56:54,248 INFO Iter : 36900 	 LR : 0.00069 	 training loss : 10.82976 	 
2025-06-12 06:58:40,889 INFO Iter : 37000 	 LR : 0.00069 	 training loss : 10.66333 	 
2025-06-12 06:59:02,292 INFO Val. loss : 4.382 	 CER : 0.0186 	 WER : 0.0901 	 
2025-06-12 07:00:59,227 INFO Iter : 37100 	 LR : 0.00069 	 training loss : 11.02727 	 
2025-06-12 07:02:47,451 INFO Iter : 37200 	 LR : 0.00069 	 training loss : 10.38716 	 
2025-06-12 07:04:33,496 INFO Iter : 37300 	 LR : 0.00069 	 training loss : 10.25492 	 
2025-06-12 07:06:23,276 INFO Iter : 37400 	 LR : 0.00069 	 training loss : 10.16701 	 
2025-06-12 07:08:12,966 INFO Iter : 37500 	 LR : 0.00069 	 training loss : 10.79088 	 
2025-06-12 07:10:01,187 INFO Iter : 37600 	 LR : 0.00068 	 training loss : 10.33872 	 
2025-06-12 07:11:49,553 INFO Iter : 37700 	 LR : 0.00068 	 training loss : 9.92401 	 
2025-06-12 07:13:39,207 INFO Iter : 37800 	 LR : 0.00068 	 training loss : 9.40926 	 
2025-06-12 07:15:26,884 INFO Iter : 37900 	 LR : 0.00068 	 training loss : 10.51570 	 
2025-06-12 07:17:15,693 INFO Iter : 38000 	 LR : 0.00068 	 training loss : 10.50864 	 
2025-06-12 07:17:38,391 INFO Val. loss : 4.374 	 CER : 0.0183 	 WER : 0.0897 	 
2025-06-12 07:19:34,661 INFO Iter : 38100 	 LR : 0.00068 	 training loss : 10.13017 	 
2025-06-12 07:21:21,982 INFO Iter : 38200 	 LR : 0.00068 	 training loss : 10.60964 	 
2025-06-12 07:23:10,421 INFO Iter : 38300 	 LR : 0.00067 	 training loss : 9.46822 	 
2025-06-12 07:24:58,820 INFO Iter : 38400 	 LR : 0.00067 	 training loss : 10.21801 	 
2025-06-12 07:26:46,220 INFO Iter : 38500 	 LR : 0.00067 	 training loss : 10.38540 	 
2025-06-12 07:28:32,926 INFO Iter : 38600 	 LR : 0.00067 	 training loss : 10.05817 	 
2025-06-12 07:30:23,220 INFO Iter : 38700 	 LR : 0.00067 	 training loss : 9.56514 	 
2025-06-12 07:32:13,193 INFO Iter : 38800 	 LR : 0.00067 	 training loss : 9.89850 	 
2025-06-12 07:34:00,190 INFO Iter : 38900 	 LR : 0.00067 	 training loss : 10.08878 	 
2025-06-12 07:35:49,832 INFO Iter : 39000 	 LR : 0.00066 	 training loss : 9.55798 	 
2025-06-12 07:36:11,053 INFO Val. loss : 4.346 	 CER : 0.0179 	 WER : 0.0871 	 
2025-06-12 07:38:05,963 INFO Iter : 39100 	 LR : 0.00066 	 training loss : 9.87064 	 
2025-06-12 07:39:54,122 INFO Iter : 39200 	 LR : 0.00066 	 training loss : 9.55382 	 
2025-06-12 07:41:43,519 INFO Iter : 39300 	 LR : 0.00066 	 training loss : 10.38983 	 
2025-06-12 07:43:34,259 INFO Iter : 39400 	 LR : 0.00066 	 training loss : 9.26105 	 
2025-06-12 07:45:23,438 INFO Iter : 39500 	 LR : 0.00066 	 training loss : 10.12519 	 
2025-06-12 07:47:10,754 INFO Iter : 39600 	 LR : 0.00065 	 training loss : 9.52156 	 
2025-06-12 07:49:02,041 INFO Iter : 39700 	 LR : 0.00065 	 training loss : 9.10669 	 
2025-06-12 07:50:50,289 INFO Iter : 39800 	 LR : 0.00065 	 training loss : 9.98605 	 
2025-06-12 07:52:37,567 INFO Iter : 39900 	 LR : 0.00065 	 training loss : 9.29190 	 
2025-06-12 07:54:25,464 INFO Iter : 40000 	 LR : 0.00065 	 training loss : 9.72959 	 
2025-06-12 07:54:46,429 INFO CER improved from 0.0179 to 0.0176!!!
2025-06-12 07:54:46,758 INFO WER improved from 0.0857 to 0.0843!!!
2025-06-12 07:54:47,039 INFO Val. loss : 4.323 	 CER : 0.0176 	 WER : 0.0843 	 
2025-06-12 07:58:08,376 INFO Iter : 40100 	 LR : 0.00065 	 training loss : 10.14981 	 
2025-06-12 07:59:57,253 INFO Iter : 40200 	 LR : 0.00065 	 training loss : 9.36920 	 
2025-06-12 08:01:47,009 INFO Iter : 40300 	 LR : 0.00064 	 training loss : 10.01874 	 
2025-06-12 08:03:35,285 INFO Iter : 40400 	 LR : 0.00064 	 training loss : 9.85423 	 
2025-06-12 08:05:23,555 INFO Iter : 40500 	 LR : 0.00064 	 training loss : 10.14281 	 
2025-06-12 08:07:15,146 INFO Iter : 40600 	 LR : 0.00064 	 training loss : 10.02548 	 
2025-06-12 08:09:03,218 INFO Iter : 40700 	 LR : 0.00064 	 training loss : 10.47194 	 
2025-06-12 08:10:50,195 INFO Iter : 40800 	 LR : 0.00064 	 training loss : 10.36498 	 
2025-06-12 08:12:39,775 INFO Iter : 40900 	 LR : 0.00063 	 training loss : 9.89599 	 
2025-06-12 08:14:29,060 INFO Iter : 41000 	 LR : 0.00063 	 training loss : 9.06707 	 
2025-06-12 08:14:49,697 INFO CER improved from 0.0176 to 0.0175!!!
2025-06-12 08:14:49,962 INFO WER improved from 0.0843 to 0.0838!!!
2025-06-12 08:14:50,259 INFO Val. loss : 4.306 	 CER : 0.0175 	 WER : 0.0838 	 
2025-06-12 08:18:10,212 INFO Iter : 41100 	 LR : 0.00063 	 training loss : 9.78600 	 
2025-06-12 08:20:01,140 INFO Iter : 41200 	 LR : 0.00063 	 training loss : 10.29678 	 
2025-06-12 08:21:47,487 INFO Iter : 41300 	 LR : 0.00063 	 training loss : 8.83983 	 
2025-06-12 08:23:35,767 INFO Iter : 41400 	 LR : 0.00063 	 training loss : 9.97644 	 
2025-06-12 08:25:27,257 INFO Iter : 41500 	 LR : 0.00063 	 training loss : 9.79796 	 
2025-06-12 08:27:15,955 INFO Iter : 41600 	 LR : 0.00062 	 training loss : 8.91218 	 
2025-06-12 08:29:03,727 INFO Iter : 41700 	 LR : 0.00062 	 training loss : 9.41563 	 
2025-06-12 08:30:53,467 INFO Iter : 41800 	 LR : 0.00062 	 training loss : 9.50563 	 
2025-06-12 08:32:41,460 INFO Iter : 41900 	 LR : 0.00062 	 training loss : 10.49985 	 
2025-06-12 08:34:28,804 INFO Iter : 42000 	 LR : 0.00062 	 training loss : 9.22999 	 
2025-06-12 08:34:49,989 INFO Val. loss : 4.264 	 CER : 0.0175 	 WER : 0.0839 	 
2025-06-12 08:36:45,843 INFO Iter : 42100 	 LR : 0.00062 	 training loss : 9.53338 	 
2025-06-12 08:38:36,530 INFO Iter : 42200 	 LR : 0.00061 	 training loss : 10.03096 	 
2025-06-12 08:40:23,918 INFO Iter : 42300 	 LR : 0.00061 	 training loss : 9.67214 	 
2025-06-12 08:42:13,235 INFO Iter : 42400 	 LR : 0.00061 	 training loss : 9.29568 	 
2025-06-12 08:44:02,410 INFO Iter : 42500 	 LR : 0.00061 	 training loss : 9.84602 	 
2025-06-12 08:45:51,190 INFO Iter : 42600 	 LR : 0.00061 	 training loss : 9.28142 	 
2025-06-12 08:47:40,774 INFO Iter : 42700 	 LR : 0.00061 	 training loss : 9.63867 	 
2025-06-12 08:49:30,906 INFO Iter : 42800 	 LR : 0.00061 	 training loss : 9.44274 	 
2025-06-12 08:51:18,079 INFO Iter : 42900 	 LR : 0.00060 	 training loss : 9.84938 	 
2025-06-12 08:53:05,655 INFO Iter : 43000 	 LR : 0.00060 	 training loss : 9.63697 	 
2025-06-12 08:53:27,266 INFO CER improved from 0.0175 to 0.0170!!!
2025-06-12 08:53:27,547 INFO WER improved from 0.0838 to 0.0834!!!
2025-06-12 08:53:27,813 INFO Val. loss : 4.218 	 CER : 0.0170 	 WER : 0.0834 	 
2025-06-12 08:56:43,291 INFO Iter : 43100 	 LR : 0.00060 	 training loss : 9.47465 	 
2025-06-12 08:58:29,246 INFO Iter : 43200 	 LR : 0.00060 	 training loss : 9.08494 	 
2025-06-12 09:00:18,112 INFO Iter : 43300 	 LR : 0.00060 	 training loss : 10.11107 	 
2025-06-12 09:02:08,059 INFO Iter : 43400 	 LR : 0.00060 	 training loss : 9.55408 	 
2025-06-12 09:03:54,803 INFO Iter : 43500 	 LR : 0.00059 	 training loss : 9.11127 	 
2025-06-12 09:05:43,561 INFO Iter : 43600 	 LR : 0.00059 	 training loss : 9.13950 	 
2025-06-12 09:07:32,585 INFO Iter : 43700 	 LR : 0.00059 	 training loss : 9.65805 	 
2025-06-12 09:09:21,145 INFO Iter : 43800 	 LR : 0.00059 	 training loss : 8.88475 	 
2025-06-12 09:11:08,884 INFO Iter : 43900 	 LR : 0.00059 	 training loss : 9.89275 	 
2025-06-12 09:12:58,124 INFO Iter : 44000 	 LR : 0.00059 	 training loss : 8.83217 	 
2025-06-12 09:13:18,916 INFO CER improved from 0.0170 to 0.0168!!!
2025-06-12 09:13:19,167 INFO WER improved from 0.0834 to 0.0826!!!
2025-06-12 09:13:19,432 INFO Val. loss : 4.212 	 CER : 0.0168 	 WER : 0.0826 	 
2025-06-12 09:16:34,243 INFO Iter : 44100 	 LR : 0.00059 	 training loss : 9.07906 	 
2025-06-12 09:18:21,873 INFO Iter : 44200 	 LR : 0.00058 	 training loss : 9.26512 	 
2025-06-12 09:20:12,349 INFO Iter : 44300 	 LR : 0.00058 	 training loss : 9.67152 	 
2025-06-12 09:21:59,649 INFO Iter : 44400 	 LR : 0.00058 	 training loss : 9.15641 	 
2025-06-12 09:23:48,610 INFO Iter : 44500 	 LR : 0.00058 	 training loss : 9.59114 	 
2025-06-12 09:25:38,381 INFO Iter : 44600 	 LR : 0.00058 	 training loss : 9.26061 	 
2025-06-12 09:27:26,441 INFO Iter : 44700 	 LR : 0.00058 	 training loss : 8.66239 	 
2025-06-12 09:29:14,758 INFO Iter : 44800 	 LR : 0.00057 	 training loss : 8.90008 	 
2025-06-12 09:31:04,231 INFO Iter : 44900 	 LR : 0.00057 	 training loss : 9.36872 	 
2025-06-12 09:32:54,238 INFO Iter : 45000 	 LR : 0.00057 	 training loss : 9.31206 	 
2025-06-12 09:33:14,691 INFO Val. loss : 4.233 	 CER : 0.0174 	 WER : 0.0835 	 
2025-06-12 09:35:06,351 INFO Iter : 45100 	 LR : 0.00057 	 training loss : 9.68042 	 
2025-06-12 09:36:57,398 INFO Iter : 45200 	 LR : 0.00057 	 training loss : 9.24360 	 
2025-06-12 09:38:45,627 INFO Iter : 45300 	 LR : 0.00057 	 training loss : 8.82057 	 
2025-06-12 09:40:33,463 INFO Iter : 45400 	 LR : 0.00056 	 training loss : 9.59296 	 
2025-06-12 09:42:22,609 INFO Iter : 45500 	 LR : 0.00056 	 training loss : 9.33319 	 
2025-06-12 09:44:11,742 INFO Iter : 45600 	 LR : 0.00056 	 training loss : 8.87070 	 
2025-06-12 09:45:59,077 INFO Iter : 45700 	 LR : 0.00056 	 training loss : 8.72930 	 
2025-06-12 09:47:48,129 INFO Iter : 45800 	 LR : 0.00056 	 training loss : 8.59206 	 
2025-06-12 09:49:37,482 INFO Iter : 45900 	 LR : 0.00056 	 training loss : 8.67154 	 
2025-06-12 09:51:26,587 INFO Iter : 46000 	 LR : 0.00056 	 training loss : 8.36455 	 
2025-06-12 09:51:48,220 INFO Val. loss : 4.231 	 CER : 0.0172 	 WER : 0.0829 	 
2025-06-12 09:53:43,344 INFO Iter : 46100 	 LR : 0.00055 	 training loss : 9.03098 	 
2025-06-12 09:55:33,467 INFO Iter : 46200 	 LR : 0.00055 	 training loss : 8.41272 	 
2025-06-12 09:57:21,326 INFO Iter : 46300 	 LR : 0.00055 	 training loss : 8.78566 	 
2025-06-12 09:59:08,577 INFO Iter : 46400 	 LR : 0.00055 	 training loss : 8.47444 	 
2025-06-12 10:01:00,277 INFO Iter : 46500 	 LR : 0.00055 	 training loss : 9.82013 	 
2025-06-12 10:02:48,290 INFO Iter : 46600 	 LR : 0.00055 	 training loss : 9.32319 	 
2025-06-12 10:04:35,582 INFO Iter : 46700 	 LR : 0.00054 	 training loss : 8.98231 	 
2025-06-12 10:06:26,035 INFO Iter : 46800 	 LR : 0.00054 	 training loss : 8.87400 	 
2025-06-12 10:08:16,510 INFO Iter : 46900 	 LR : 0.00054 	 training loss : 8.90005 	 
2025-06-12 10:10:03,720 INFO Iter : 47000 	 LR : 0.00054 	 training loss : 8.54224 	 
2025-06-12 10:10:25,348 INFO WER improved from 0.0826 to 0.0823!!!
2025-06-12 10:10:25,645 INFO Val. loss : 4.211 	 CER : 0.0172 	 WER : 0.0823 	 
2025-06-12 10:13:26,758 INFO Iter : 47100 	 LR : 0.00054 	 training loss : 8.95015 	 
2025-06-12 10:15:15,096 INFO Iter : 47200 	 LR : 0.00054 	 training loss : 8.89092 	 
2025-06-12 10:17:02,057 INFO Iter : 47300 	 LR : 0.00053 	 training loss : 9.18390 	 
2025-06-12 10:18:52,621 INFO Iter : 47400 	 LR : 0.00053 	 training loss : 8.54643 	 
2025-06-12 10:20:41,350 INFO Iter : 47500 	 LR : 0.00053 	 training loss : 8.76787 	 
2025-06-12 10:22:26,118 INFO Iter : 47600 	 LR : 0.00053 	 training loss : 9.12667 	 
2025-06-12 10:24:13,422 INFO Iter : 47700 	 LR : 0.00053 	 training loss : 9.10685 	 
2025-06-12 10:26:03,678 INFO Iter : 47800 	 LR : 0.00053 	 training loss : 8.26846 	 
2025-06-12 10:27:50,910 INFO Iter : 47900 	 LR : 0.00053 	 training loss : 8.80782 	 
2025-06-12 10:29:37,661 INFO Iter : 48000 	 LR : 0.00052 	 training loss : 8.49760 	 
2025-06-12 10:30:01,485 INFO Val. loss : 4.236 	 CER : 0.0173 	 WER : 0.0841 	 
2025-06-12 10:31:56,767 INFO Iter : 48100 	 LR : 0.00052 	 training loss : 8.53041 	 
2025-06-12 10:33:44,917 INFO Iter : 48200 	 LR : 0.00052 	 training loss : 8.58086 	 
2025-06-12 10:35:32,781 INFO Iter : 48300 	 LR : 0.00052 	 training loss : 8.13906 	 
2025-06-12 10:37:23,228 INFO Iter : 48400 	 LR : 0.00052 	 training loss : 9.05821 	 
2025-06-12 10:39:09,712 INFO Iter : 48500 	 LR : 0.00052 	 training loss : 8.93189 	 
2025-06-12 10:40:56,497 INFO Iter : 48600 	 LR : 0.00051 	 training loss : 9.12598 	 
2025-06-12 10:42:45,515 INFO Iter : 48700 	 LR : 0.00051 	 training loss : 8.31285 	 
2025-06-12 10:44:34,503 INFO Iter : 48800 	 LR : 0.00051 	 training loss : 8.58792 	 
2025-06-12 10:46:20,336 INFO Iter : 48900 	 LR : 0.00051 	 training loss : 8.63301 	 
2025-06-12 10:48:08,732 INFO Iter : 49000 	 LR : 0.00051 	 training loss : 8.62923 	 
2025-06-12 10:48:29,913 INFO Val. loss : 4.218 	 CER : 0.0169 	 WER : 0.0831 	 
2025-06-12 10:50:31,870 INFO Iter : 49100 	 LR : 0.00051 	 training loss : 8.41150 	 
2025-06-12 10:52:20,608 INFO Iter : 49200 	 LR : 0.00050 	 training loss : 8.23066 	 
2025-06-12 10:54:08,727 INFO Iter : 49300 	 LR : 0.00050 	 training loss : 8.58853 	 
2025-06-12 10:56:01,117 INFO Iter : 49400 	 LR : 0.00050 	 training loss : 8.01751 	 
2025-06-12 10:57:49,919 INFO Iter : 49500 	 LR : 0.00050 	 training loss : 9.25558 	 
2025-06-12 10:59:39,976 INFO Iter : 49600 	 LR : 0.00050 	 training loss : 9.50038 	 
2025-06-12 11:01:30,220 INFO Iter : 49700 	 LR : 0.00050 	 training loss : 7.88867 	 
2025-06-12 11:03:18,113 INFO Iter : 49800 	 LR : 0.00050 	 training loss : 8.04247 	 
2025-06-12 11:05:06,268 INFO Iter : 49900 	 LR : 0.00049 	 training loss : 8.95378 	 
2025-06-12 11:06:56,652 INFO Iter : 50000 	 LR : 0.00049 	 training loss : 7.87788 	 
2025-06-12 11:07:18,258 INFO Val. loss : 4.184 	 CER : 0.0171 	 WER : 0.0841 	 
2025-06-12 11:09:12,774 INFO Iter : 50100 	 LR : 0.00049 	 training loss : 8.51700 	 
2025-06-12 11:10:59,399 INFO Iter : 50200 	 LR : 0.00049 	 training loss : 8.48704 	 
2025-06-12 11:12:47,479 INFO Iter : 50300 	 LR : 0.00049 	 training loss : 8.37403 	 
2025-06-12 11:14:36,231 INFO Iter : 50400 	 LR : 0.00049 	 training loss : 8.09968 	 
2025-06-12 11:16:24,098 INFO Iter : 50500 	 LR : 0.00048 	 training loss : 8.56222 	 
2025-06-12 11:18:13,271 INFO Iter : 50600 	 LR : 0.00048 	 training loss : 8.42005 	 
2025-06-12 11:20:04,286 INFO Iter : 50700 	 LR : 0.00048 	 training loss : 8.27915 	 
2025-06-12 11:21:52,942 INFO Iter : 50800 	 LR : 0.00048 	 training loss : 8.46987 	 
2025-06-12 11:23:40,804 INFO Iter : 50900 	 LR : 0.00048 	 training loss : 8.74635 	 
2025-06-12 11:25:28,944 INFO Iter : 51000 	 LR : 0.00048 	 training loss : 8.38404 	 
2025-06-12 11:25:48,596 INFO Val. loss : 4.175 	 CER : 0.0171 	 WER : 0.0837 	 
2025-06-12 11:27:41,300 INFO Iter : 51100 	 LR : 0.00047 	 training loss : 7.55232 	 
2025-06-12 11:29:28,414 INFO Iter : 51200 	 LR : 0.00047 	 training loss : 7.60483 	 
2025-06-12 11:31:18,650 INFO Iter : 51300 	 LR : 0.00047 	 training loss : 8.81586 	 
2025-06-12 11:33:08,565 INFO Iter : 51400 	 LR : 0.00047 	 training loss : 8.10181 	 
2025-06-12 11:34:57,109 INFO Iter : 51500 	 LR : 0.00047 	 training loss : 8.07015 	 
2025-06-12 11:36:47,260 INFO Iter : 51600 	 LR : 0.00047 	 training loss : 8.14869 	 
2025-06-12 11:38:33,456 INFO Iter : 51700 	 LR : 0.00047 	 training loss : 8.25051 	 
2025-06-12 11:40:20,451 INFO Iter : 51800 	 LR : 0.00046 	 training loss : 7.75651 	 
2025-06-12 11:42:10,146 INFO Iter : 51900 	 LR : 0.00046 	 training loss : 8.37553 	 
2025-06-12 11:44:00,271 INFO Iter : 52000 	 LR : 0.00046 	 training loss : 7.74845 	 
2025-06-12 11:44:20,720 INFO WER improved from 0.0823 to 0.0819!!!
2025-06-12 11:44:20,969 INFO Val. loss : 4.150 	 CER : 0.0168 	 WER : 0.0819 	 
2025-06-12 11:47:01,854 INFO Iter : 52100 	 LR : 0.00046 	 training loss : 8.24323 	 
2025-06-12 11:48:52,283 INFO Iter : 52200 	 LR : 0.00046 	 training loss : 8.14051 	 
2025-06-12 11:50:42,481 INFO Iter : 52300 	 LR : 0.00046 	 training loss : 7.51731 	 
2025-06-12 11:52:27,746 INFO Iter : 52400 	 LR : 0.00045 	 training loss : 7.94366 	 
2025-06-12 11:54:16,364 INFO Iter : 52500 	 LR : 0.00045 	 training loss : 7.66043 	 
2025-06-12 11:56:07,202 INFO Iter : 52600 	 LR : 0.00045 	 training loss : 7.44165 	 
2025-06-12 11:57:54,784 INFO Iter : 52700 	 LR : 0.00045 	 training loss : 7.66403 	 
2025-06-12 11:59:42,177 INFO Iter : 52800 	 LR : 0.00045 	 training loss : 7.64057 	 
2025-06-12 12:01:33,029 INFO Iter : 52900 	 LR : 0.00045 	 training loss : 7.94310 	 
2025-06-12 12:03:22,225 INFO Iter : 53000 	 LR : 0.00044 	 training loss : 8.03451 	 
2025-06-12 12:03:44,206 INFO CER improved from 0.0168 to 0.0166!!!
2025-06-12 12:03:44,503 INFO WER improved from 0.0819 to 0.0815!!!
2025-06-12 12:03:44,784 INFO Val. loss : 4.157 	 CER : 0.0166 	 WER : 0.0815 	 
2025-06-12 12:07:03,727 INFO Iter : 53100 	 LR : 0.00044 	 training loss : 7.50860 	 
2025-06-12 12:08:52,066 INFO Iter : 53200 	 LR : 0.00044 	 training loss : 8.49640 	 
2025-06-12 12:10:39,944 INFO Iter : 53300 	 LR : 0.00044 	 training loss : 8.04415 	 
2025-06-12 12:12:30,300 INFO Iter : 53400 	 LR : 0.00044 	 training loss : 7.72176 	 
2025-06-12 12:14:20,054 INFO Iter : 53500 	 LR : 0.00044 	 training loss : 7.62541 	 
2025-06-12 12:16:06,595 INFO Iter : 53600 	 LR : 0.00044 	 training loss : 7.71006 	 
2025-06-12 12:17:54,506 INFO Iter : 53700 	 LR : 0.00043 	 training loss : 8.44354 	 
2025-06-12 12:19:42,109 INFO Iter : 53800 	 LR : 0.00043 	 training loss : 7.60374 	 
2025-06-12 12:21:29,275 INFO Iter : 53900 	 LR : 0.00043 	 training loss : 7.29595 	 
2025-06-12 12:23:16,193 INFO Iter : 54000 	 LR : 0.00043 	 training loss : 7.44531 	 
2025-06-12 12:23:38,285 INFO CER improved from 0.0166 to 0.0165!!!
2025-06-12 12:23:38,551 INFO WER improved from 0.0815 to 0.0806!!!
2025-06-12 12:23:38,801 INFO Val. loss : 4.172 	 CER : 0.0165 	 WER : 0.0806 	 
2025-06-12 12:26:57,175 INFO Iter : 54100 	 LR : 0.00043 	 training loss : 7.45850 	 
2025-06-12 12:28:43,078 INFO Iter : 54200 	 LR : 0.00043 	 training loss : 7.05435 	 
2025-06-12 12:30:32,707 INFO Iter : 54300 	 LR : 0.00042 	 training loss : 7.84143 	 
2025-06-12 12:32:22,713 INFO Iter : 54400 	 LR : 0.00042 	 training loss : 7.81885 	 
2025-06-12 12:34:08,960 INFO Iter : 54500 	 LR : 0.00042 	 training loss : 7.77344 	 
2025-06-12 12:35:56,522 INFO Iter : 54600 	 LR : 0.00042 	 training loss : 7.74071 	 
2025-06-12 12:37:46,669 INFO Iter : 54700 	 LR : 0.00042 	 training loss : 7.79589 	 
2025-06-12 12:39:34,197 INFO Iter : 54800 	 LR : 0.00042 	 training loss : 7.55819 	 
2025-06-12 12:41:21,411 INFO Iter : 54900 	 LR : 0.00041 	 training loss : 7.95896 	 
2025-06-12 12:43:11,259 INFO Iter : 55000 	 LR : 0.00041 	 training loss : 7.35818 	 
2025-06-12 12:43:31,412 INFO CER improved from 0.0165 to 0.0164!!!
2025-06-12 12:43:31,694 INFO WER improved from 0.0806 to 0.0795!!!
2025-06-12 12:43:32,022 INFO Val. loss : 4.169 	 CER : 0.0164 	 WER : 0.0795 	 
2025-06-12 12:46:47,682 INFO Iter : 55100 	 LR : 0.00041 	 training loss : 7.44362 	 
2025-06-12 12:48:36,257 INFO Iter : 55200 	 LR : 0.00041 	 training loss : 7.31059 	 
2025-06-12 12:50:25,737 INFO Iter : 55300 	 LR : 0.00041 	 training loss : 7.10659 	 
2025-06-12 12:52:13,990 INFO Iter : 55400 	 LR : 0.00041 	 training loss : 7.51162 	 
2025-06-12 12:54:02,764 INFO Iter : 55500 	 LR : 0.00041 	 training loss : 7.93329 	 
2025-06-12 12:55:50,916 INFO Iter : 55600 	 LR : 0.00040 	 training loss : 7.24923 	 
2025-06-12 12:57:38,868 INFO Iter : 55700 	 LR : 0.00040 	 training loss : 7.36525 	 
2025-06-12 12:59:25,397 INFO Iter : 55800 	 LR : 0.00040 	 training loss : 7.63318 	 
2025-06-12 13:01:16,929 INFO Iter : 55900 	 LR : 0.00040 	 training loss : 8.16077 	 
2025-06-12 13:03:06,418 INFO Iter : 56000 	 LR : 0.00040 	 training loss : 8.02600 	 
2025-06-12 13:03:27,865 INFO Val. loss : 4.167 	 CER : 0.0167 	 WER : 0.0803 	 
2025-06-12 13:05:20,166 INFO Iter : 56100 	 LR : 0.00040 	 training loss : 7.88985 	 
2025-06-12 13:07:10,381 INFO Iter : 56200 	 LR : 0.00039 	 training loss : 7.57835 	 
2025-06-12 13:08:59,554 INFO Iter : 56300 	 LR : 0.00039 	 training loss : 7.32228 	 
2025-06-12 13:10:47,605 INFO Iter : 56400 	 LR : 0.00039 	 training loss : 7.07046 	 
2025-06-12 13:12:37,586 INFO Iter : 56500 	 LR : 0.00039 	 training loss : 7.30465 	 
2025-06-12 13:14:24,999 INFO Iter : 56600 	 LR : 0.00039 	 training loss : 7.70171 	 
2025-06-12 13:16:13,383 INFO Iter : 56700 	 LR : 0.00039 	 training loss : 6.65840 	 
2025-06-12 13:18:02,422 INFO Iter : 56800 	 LR : 0.00039 	 training loss : 7.46425 	 
2025-06-12 13:19:52,491 INFO Iter : 56900 	 LR : 0.00038 	 training loss : 7.35942 	 
2025-06-12 13:21:40,326 INFO Iter : 57000 	 LR : 0.00038 	 training loss : 7.24574 	 
2025-06-12 13:22:01,062 INFO Val. loss : 4.132 	 CER : 0.0166 	 WER : 0.0806 	 
2025-06-12 13:23:54,707 INFO Iter : 57100 	 LR : 0.00038 	 training loss : 7.72678 	 
2025-06-12 13:25:46,944 INFO Iter : 57200 	 LR : 0.00038 	 training loss : 7.06516 	 
2025-06-12 13:27:35,377 INFO Iter : 57300 	 LR : 0.00038 	 training loss : 7.05554 	 
2025-06-12 13:29:22,441 INFO Iter : 57400 	 LR : 0.00038 	 training loss : 7.60154 	 
2025-06-12 13:31:11,653 INFO Iter : 57500 	 LR : 0.00037 	 training loss : 7.41674 	 
2025-06-12 13:32:59,642 INFO Iter : 57600 	 LR : 0.00037 	 training loss : 7.61067 	 
2025-06-12 13:34:46,569 INFO Iter : 57700 	 LR : 0.00037 	 training loss : 7.07258 	 
2025-06-12 13:36:34,341 INFO Iter : 57800 	 LR : 0.00037 	 training loss : 6.70875 	 
2025-06-12 13:38:22,898 INFO Iter : 57900 	 LR : 0.00037 	 training loss : 6.82656 	 
2025-06-12 13:40:10,121 INFO Iter : 58000 	 LR : 0.00037 	 training loss : 7.31761 	 
2025-06-12 13:40:32,397 INFO Val. loss : 4.121 	 CER : 0.0164 	 WER : 0.0799 	 
2025-06-12 13:42:28,605 INFO Iter : 58100 	 LR : 0.00037 	 training loss : 7.32896 	 
2025-06-12 13:44:20,136 INFO Iter : 58200 	 LR : 0.00036 	 training loss : 6.60109 	 
2025-06-12 13:46:07,060 INFO Iter : 58300 	 LR : 0.00036 	 training loss : 6.82037 	 
2025-06-12 13:47:56,815 INFO Iter : 58400 	 LR : 0.00036 	 training loss : 7.14247 	 
2025-06-12 13:49:45,439 INFO Iter : 58500 	 LR : 0.00036 	 training loss : 7.74026 	 
2025-06-12 13:51:33,494 INFO Iter : 58600 	 LR : 0.00036 	 training loss : 6.61538 	 
2025-06-12 13:53:22,577 INFO Iter : 58700 	 LR : 0.00036 	 training loss : 7.13913 	 
2025-06-12 13:55:12,549 INFO Iter : 58800 	 LR : 0.00035 	 training loss : 6.65729 	 
2025-06-12 13:57:01,881 INFO Iter : 58900 	 LR : 0.00035 	 training loss : 7.34927 	 
2025-06-12 13:58:50,803 INFO Iter : 59000 	 LR : 0.00035 	 training loss : 7.24751 	 
2025-06-12 13:59:10,960 INFO CER improved from 0.0164 to 0.0162!!!
2025-06-12 13:59:11,210 INFO WER improved from 0.0795 to 0.0794!!!
2025-06-12 13:59:11,460 INFO Val. loss : 4.126 	 CER : 0.0162 	 WER : 0.0794 	 
2025-06-12 14:02:29,000 INFO Iter : 59100 	 LR : 0.00035 	 training loss : 6.54290 	 
2025-06-12 14:04:16,495 INFO Iter : 59200 	 LR : 0.00035 	 training loss : 6.78269 	 
2025-06-12 14:06:06,434 INFO Iter : 59300 	 LR : 0.00035 	 training loss : 6.87072 	 
2025-06-12 14:07:56,142 INFO Iter : 59400 	 LR : 0.00035 	 training loss : 7.41533 	 
2025-06-12 14:09:43,289 INFO Iter : 59500 	 LR : 0.00034 	 training loss : 6.89141 	 
2025-06-12 14:11:32,491 INFO Iter : 59600 	 LR : 0.00034 	 training loss : 7.16154 	 
2025-06-12 14:13:24,376 INFO Iter : 59700 	 LR : 0.00034 	 training loss : 6.49899 	 
2025-06-12 14:15:13,854 INFO Iter : 59800 	 LR : 0.00034 	 training loss : 6.60280 	 
2025-06-12 14:17:00,434 INFO Iter : 59900 	 LR : 0.00034 	 training loss : 6.69878 	 
2025-06-12 14:18:49,142 INFO Iter : 60000 	 LR : 0.00034 	 training loss : 6.78190 	 
2025-06-12 14:19:10,684 INFO CER improved from 0.0162 to 0.0162!!!
2025-06-12 14:19:10,966 INFO Val. loss : 4.110 	 CER : 0.0162 	 WER : 0.0799 	 
2025-06-12 14:21:54,490 INFO Iter : 60100 	 LR : 0.00034 	 training loss : 6.88981 	 
2025-06-12 14:23:42,889 INFO Iter : 60200 	 LR : 0.00033 	 training loss : 6.72489 	 
2025-06-12 14:25:32,926 INFO Iter : 60300 	 LR : 0.00033 	 training loss : 7.50102 	 
2025-06-12 14:27:19,847 INFO Iter : 60400 	 LR : 0.00033 	 training loss : 6.93857 	 
2025-06-12 14:29:08,226 INFO Iter : 60500 	 LR : 0.00033 	 training loss : 6.84840 	 
2025-06-12 14:30:56,459 INFO Iter : 60600 	 LR : 0.00033 	 training loss : 7.11270 	 
2025-06-12 14:32:46,610 INFO Iter : 60700 	 LR : 0.00033 	 training loss : 7.19458 	 
2025-06-12 14:34:33,542 INFO Iter : 60800 	 LR : 0.00032 	 training loss : 6.34820 	 
2025-06-12 14:36:22,732 INFO Iter : 60900 	 LR : 0.00032 	 training loss : 7.54648 	 
2025-06-12 14:38:11,558 INFO Iter : 61000 	 LR : 0.00032 	 training loss : 6.91128 	 
2025-06-12 14:38:32,508 INFO CER improved from 0.0162 to 0.0161!!!
2025-06-12 14:38:32,774 INFO WER improved from 0.0794 to 0.0783!!!
2025-06-12 14:38:33,086 INFO Val. loss : 4.097 	 CER : 0.0161 	 WER : 0.0783 	 
2025-06-12 14:42:00,009 INFO Iter : 61100 	 LR : 0.00032 	 training loss : 6.33878 	 
2025-06-12 14:43:49,277 INFO Iter : 61200 	 LR : 0.00032 	 training loss : 6.42854 	 
2025-06-12 14:45:35,743 INFO Iter : 61300 	 LR : 0.00032 	 training loss : 6.79448 	 
2025-06-12 14:47:24,618 INFO Iter : 61400 	 LR : 0.00032 	 training loss : 6.96143 	 
2025-06-12 14:49:14,007 INFO Iter : 61500 	 LR : 0.00031 	 training loss : 6.75825 	 
2025-06-12 14:51:03,970 INFO Iter : 61600 	 LR : 0.00031 	 training loss : 6.83392 	 
2025-06-12 14:52:50,521 INFO Iter : 61700 	 LR : 0.00031 	 training loss : 6.49703 	 
2025-06-12 14:54:38,226 INFO Iter : 61800 	 LR : 0.00031 	 training loss : 6.66965 	 
2025-06-12 14:56:25,924 INFO Iter : 61900 	 LR : 0.00031 	 training loss : 6.62727 	 
2025-06-12 14:58:13,486 INFO Iter : 62000 	 LR : 0.00031 	 training loss : 6.45802 	 
2025-06-12 14:58:34,843 INFO WER improved from 0.0783 to 0.0779!!!
2025-06-12 14:58:35,093 INFO Val. loss : 4.088 	 CER : 0.0161 	 WER : 0.0779 	 
2025-06-12 15:01:23,574 INFO Iter : 62100 	 LR : 0.00031 	 training loss : 6.36998 	 
2025-06-12 15:03:10,612 INFO Iter : 62200 	 LR : 0.00030 	 training loss : 6.37739 	 
2025-06-12 15:04:57,514 INFO Iter : 62300 	 LR : 0.00030 	 training loss : 6.06609 	 
2025-06-12 15:06:46,684 INFO Iter : 62400 	 LR : 0.00030 	 training loss : 6.66536 	 
2025-06-12 15:08:37,162 INFO Iter : 62500 	 LR : 0.00030 	 training loss : 6.48227 	 
2025-06-12 15:10:24,057 INFO Iter : 62600 	 LR : 0.00030 	 training loss : 6.45845 	 
2025-06-12 15:12:14,701 INFO Iter : 62700 	 LR : 0.00030 	 training loss : 6.06332 	 
2025-06-12 15:14:05,046 INFO Iter : 62800 	 LR : 0.00030 	 training loss : 6.14895 	 
2025-06-12 15:15:51,526 INFO Iter : 62900 	 LR : 0.00029 	 training loss : 6.75952 	 
2025-06-12 15:17:39,905 INFO Iter : 63000 	 LR : 0.00029 	 training loss : 6.20796 	 
2025-06-12 15:18:02,301 INFO CER improved from 0.0161 to 0.0160!!!
2025-06-12 15:18:02,566 INFO Val. loss : 4.086 	 CER : 0.0160 	 WER : 0.0781 	 
2025-06-12 15:20:45,812 INFO Iter : 63100 	 LR : 0.00029 	 training loss : 6.00736 	 
2025-06-12 15:22:33,211 INFO Iter : 63200 	 LR : 0.00029 	 training loss : 5.80594 	 
2025-06-12 15:24:23,113 INFO Iter : 63300 	 LR : 0.00029 	 training loss : 5.87931 	 
2025-06-12 15:26:11,558 INFO Iter : 63400 	 LR : 0.00029 	 training loss : 5.95729 	 
2025-06-12 15:27:58,450 INFO Iter : 63500 	 LR : 0.00029 	 training loss : 6.78911 	 
2025-06-12 15:29:47,386 INFO Iter : 63600 	 LR : 0.00028 	 training loss : 6.19602 	 
2025-06-12 15:31:37,706 INFO Iter : 63700 	 LR : 0.00028 	 training loss : 5.93445 	 
2025-06-12 15:33:25,118 INFO Iter : 63800 	 LR : 0.00028 	 training loss : 6.27594 	 
2025-06-12 15:35:14,030 INFO Iter : 63900 	 LR : 0.00028 	 training loss : 6.56170 	 
2025-06-12 15:37:04,726 INFO Iter : 64000 	 LR : 0.00028 	 training loss : 6.40081 	 
2025-06-12 15:37:25,564 INFO CER improved from 0.0160 to 0.0159!!!
2025-06-12 15:37:25,924 INFO Val. loss : 4.082 	 CER : 0.0159 	 WER : 0.0779 	 
2025-06-12 15:40:07,740 INFO Iter : 64100 	 LR : 0.00028 	 training loss : 6.00618 	 
2025-06-12 15:41:55,888 INFO Iter : 64200 	 LR : 0.00028 	 training loss : 6.32515 	 
2025-06-12 15:43:43,392 INFO Iter : 64300 	 LR : 0.00027 	 training loss : 6.30654 	 
2025-06-12 15:45:30,691 INFO Iter : 64400 	 LR : 0.00027 	 training loss : 5.74533 	 
2025-06-12 15:47:18,912 INFO Iter : 64500 	 LR : 0.00027 	 training loss : 6.23558 	 
2025-06-12 15:49:07,633 INFO Iter : 64600 	 LR : 0.00027 	 training loss : 6.05245 	 
2025-06-12 15:50:55,846 INFO Iter : 64700 	 LR : 0.00027 	 training loss : 6.13683 	 
2025-06-12 15:52:44,450 INFO Iter : 64800 	 LR : 0.00027 	 training loss : 6.01463 	 
2025-06-12 15:54:35,354 INFO Iter : 64900 	 LR : 0.00027 	 training loss : 6.44054 	 
2025-06-12 15:56:24,865 INFO Iter : 65000 	 LR : 0.00026 	 training loss : 5.70723 	 
2025-06-12 15:56:46,364 INFO CER improved from 0.0159 to 0.0159!!!
2025-06-12 15:56:46,676 INFO WER improved from 0.0779 to 0.0771!!!
2025-06-12 15:56:46,942 INFO Val. loss : 4.080 	 CER : 0.0159 	 WER : 0.0771 	 
2025-06-12 16:00:09,943 INFO Iter : 65100 	 LR : 0.00026 	 training loss : 5.73314 	 
2025-06-12 16:02:00,100 INFO Iter : 65200 	 LR : 0.00026 	 training loss : 5.61671 	 
2025-06-12 16:03:47,322 INFO Iter : 65300 	 LR : 0.00026 	 training loss : 6.33106 	 
2025-06-12 16:05:36,757 INFO Iter : 65400 	 LR : 0.00026 	 training loss : 5.59971 	 
2025-06-12 16:07:26,972 INFO Iter : 65500 	 LR : 0.00026 	 training loss : 6.02579 	 
2025-06-12 16:09:15,724 INFO Iter : 65600 	 LR : 0.00026 	 training loss : 6.07207 	 
2025-06-12 16:11:02,725 INFO Iter : 65700 	 LR : 0.00025 	 training loss : 6.52614 	 
2025-06-12 16:12:52,471 INFO Iter : 65800 	 LR : 0.00025 	 training loss : 6.28718 	 
2025-06-12 16:14:43,096 INFO Iter : 65900 	 LR : 0.00025 	 training loss : 6.06942 	 
2025-06-12 16:16:30,541 INFO Iter : 66000 	 LR : 0.00025 	 training loss : 5.82825 	 
2025-06-12 16:16:52,820 INFO CER improved from 0.0159 to 0.0158!!!
2025-06-12 16:16:53,070 INFO WER improved from 0.0771 to 0.0763!!!
2025-06-12 16:16:53,367 INFO Val. loss : 4.070 	 CER : 0.0158 	 WER : 0.0763 	 
2025-06-12 16:20:17,903 INFO Iter : 66100 	 LR : 0.00025 	 training loss : 5.69201 	 
2025-06-12 16:22:04,712 INFO Iter : 66200 	 LR : 0.00025 	 training loss : 5.98146 	 
2025-06-12 16:23:53,268 INFO Iter : 66300 	 LR : 0.00025 	 training loss : 5.45496 	 
2025-06-12 16:25:45,164 INFO Iter : 66400 	 LR : 0.00024 	 training loss : 6.57609 	 
2025-06-12 16:27:34,566 INFO Iter : 66500 	 LR : 0.00024 	 training loss : 6.55517 	 
2025-06-12 16:29:23,348 INFO Iter : 66600 	 LR : 0.00024 	 training loss : 6.22177 	 
2025-06-12 16:31:12,300 INFO Iter : 66700 	 LR : 0.00024 	 training loss : 5.88368 	 
2025-06-12 16:33:00,010 INFO Iter : 66800 	 LR : 0.00024 	 training loss : 5.07523 	 
2025-06-12 16:34:48,617 INFO Iter : 66900 	 LR : 0.00024 	 training loss : 5.76038 	 
2025-06-12 16:36:37,900 INFO Iter : 67000 	 LR : 0.00024 	 training loss : 5.98428 	 
2025-06-12 16:36:59,079 INFO Val. loss : 4.099 	 CER : 0.0159 	 WER : 0.0778 	 
2025-06-12 16:38:52,743 INFO Iter : 67100 	 LR : 0.00024 	 training loss : 5.86813 	 
2025-06-12 16:40:39,744 INFO Iter : 67200 	 LR : 0.00023 	 training loss : 5.50732 	 
2025-06-12 16:42:30,141 INFO Iter : 67300 	 LR : 0.00023 	 training loss : 5.53191 	 
2025-06-12 16:44:20,279 INFO Iter : 67400 	 LR : 0.00023 	 training loss : 6.37685 	 
2025-06-12 16:46:08,348 INFO Iter : 67500 	 LR : 0.00023 	 training loss : 5.67888 	 
2025-06-12 16:47:56,609 INFO Iter : 67600 	 LR : 0.00023 	 training loss : 5.48204 	 
2025-06-12 16:49:46,094 INFO Iter : 67700 	 LR : 0.00023 	 training loss : 6.27912 	 
2025-06-12 16:51:33,112 INFO Iter : 67800 	 LR : 0.00023 	 training loss : 5.36702 	 
2025-06-12 16:53:19,031 INFO Iter : 67900 	 LR : 0.00022 	 training loss : 4.92239 	 
2025-06-12 16:55:08,762 INFO Iter : 68000 	 LR : 0.00022 	 training loss : 5.67838 	 
2025-06-12 16:55:28,869 INFO Val. loss : 4.077 	 CER : 0.0158 	 WER : 0.0774 	 
2025-06-12 16:57:21,746 INFO Iter : 68100 	 LR : 0.00022 	 training loss : 5.94160 	 
2025-06-12 16:59:08,991 INFO Iter : 68200 	 LR : 0.00022 	 training loss : 5.25880 	 
2025-06-12 17:00:57,081 INFO Iter : 68300 	 LR : 0.00022 	 training loss : 5.12351 	 
2025-06-12 17:02:42,883 INFO Iter : 68400 	 LR : 0.00022 	 training loss : 5.43518 	 
2025-06-12 17:04:30,173 INFO Iter : 68500 	 LR : 0.00022 	 training loss : 5.68133 	 
2025-06-12 17:06:20,047 INFO Iter : 68600 	 LR : 0.00022 	 training loss : 5.49115 	 
2025-06-12 17:08:09,682 INFO Iter : 68700 	 LR : 0.00021 	 training loss : 5.31802 	 
2025-06-12 17:09:58,056 INFO Iter : 68800 	 LR : 0.00021 	 training loss : 5.37015 	 
2025-06-12 17:11:45,052 INFO Iter : 68900 	 LR : 0.00021 	 training loss : 6.07461 	 
2025-06-12 17:13:34,718 INFO Iter : 69000 	 LR : 0.00021 	 training loss : 5.81951 	 
2025-06-12 17:13:54,884 INFO CER improved from 0.0158 to 0.0156!!!
2025-06-12 17:13:55,165 INFO WER improved from 0.0763 to 0.0757!!!
2025-06-12 17:13:55,477 INFO Val. loss : 4.062 	 CER : 0.0156 	 WER : 0.0757 	 
2025-06-12 17:17:16,275 INFO Iter : 69100 	 LR : 0.00021 	 training loss : 5.52716 	 
2025-06-12 17:19:05,885 INFO Iter : 69200 	 LR : 0.00021 	 training loss : 5.20223 	 
2025-06-12 17:20:53,737 INFO Iter : 69300 	 LR : 0.00021 	 training loss : 5.80449 	 
2025-06-12 17:22:40,998 INFO Iter : 69400 	 LR : 0.00020 	 training loss : 5.83779 	 
2025-06-12 17:24:28,575 INFO Iter : 69500 	 LR : 0.00020 	 training loss : 5.24285 	 
2025-06-12 17:26:19,718 INFO Iter : 69600 	 LR : 0.00020 	 training loss : 5.39723 	 
2025-06-12 17:28:07,141 INFO Iter : 69700 	 LR : 0.00020 	 training loss : 5.86210 	 
2025-06-12 17:29:55,152 INFO Iter : 69800 	 LR : 0.00020 	 training loss : 5.41362 	 
2025-06-12 17:31:45,216 INFO Iter : 69900 	 LR : 0.00020 	 training loss : 5.58559 	 
2025-06-12 17:33:33,758 INFO Iter : 70000 	 LR : 0.00020 	 training loss : 5.37949 	 
2025-06-12 17:33:55,303 INFO CER improved from 0.0156 to 0.0155!!!
2025-06-12 17:33:55,569 INFO WER improved from 0.0757 to 0.0755!!!
2025-06-12 17:33:55,883 INFO Val. loss : 4.048 	 CER : 0.0155 	 WER : 0.0755 	 
2025-06-12 17:37:13,370 INFO Iter : 70100 	 LR : 0.00020 	 training loss : 4.87145 	 
2025-06-12 17:39:01,734 INFO Iter : 70200 	 LR : 0.00019 	 training loss : 5.06436 	 
2025-06-12 17:40:49,788 INFO Iter : 70300 	 LR : 0.00019 	 training loss : 5.84975 	 
2025-06-12 17:42:37,189 INFO Iter : 70400 	 LR : 0.00019 	 training loss : 5.48337 	 
2025-06-12 17:44:26,817 INFO Iter : 70500 	 LR : 0.00019 	 training loss : 5.39568 	 
2025-06-12 17:46:14,568 INFO Iter : 70600 	 LR : 0.00019 	 training loss : 5.34073 	 
2025-06-12 17:48:05,861 INFO Iter : 70700 	 LR : 0.00019 	 training loss : 5.34794 	 
2025-06-12 17:49:56,402 INFO Iter : 70800 	 LR : 0.00019 	 training loss : 4.92869 	 
2025-06-12 17:51:42,520 INFO Iter : 70900 	 LR : 0.00019 	 training loss : 5.10898 	 
2025-06-12 17:53:30,879 INFO Iter : 71000 	 LR : 0.00018 	 training loss : 4.95347 	 
2025-06-12 17:53:53,621 INFO WER improved from 0.0755 to 0.0753!!!
2025-06-12 17:53:53,902 INFO Val. loss : 4.044 	 CER : 0.0155 	 WER : 0.0753 	 
2025-06-12 17:56:37,504 INFO Iter : 71100 	 LR : 0.00018 	 training loss : 5.09070 	 
2025-06-12 17:58:25,242 INFO Iter : 71200 	 LR : 0.00018 	 training loss : 5.02078 	 
2025-06-12 18:00:14,352 INFO Iter : 71300 	 LR : 0.00018 	 training loss : 5.61134 	 
2025-06-12 18:02:03,951 INFO Iter : 71400 	 LR : 0.00018 	 training loss : 5.36884 	 
2025-06-12 18:03:52,667 INFO Iter : 71500 	 LR : 0.00018 	 training loss : 5.07114 	 
2025-06-12 18:05:42,041 INFO Iter : 71600 	 LR : 0.00018 	 training loss : 5.04240 	 
2025-06-12 18:07:31,513 INFO Iter : 71700 	 LR : 0.00018 	 training loss : 4.66237 	 
2025-06-12 18:09:19,897 INFO Iter : 71800 	 LR : 0.00018 	 training loss : 5.69431 	 
2025-06-12 18:11:07,717 INFO Iter : 71900 	 LR : 0.00017 	 training loss : 5.49106 	 
2025-06-12 18:12:57,335 INFO Iter : 72000 	 LR : 0.00017 	 training loss : 4.90849 	 
2025-06-12 18:13:19,159 INFO CER improved from 0.0155 to 0.0152!!!
2025-06-12 18:13:19,425 INFO WER improved from 0.0753 to 0.0738!!!
2025-06-12 18:13:19,691 INFO Val. loss : 4.004 	 CER : 0.0152 	 WER : 0.0738 	 
2025-06-12 18:16:36,950 INFO Iter : 72100 	 LR : 0.00017 	 training loss : 5.18808 	 
2025-06-12 18:18:27,299 INFO Iter : 72200 	 LR : 0.00017 	 training loss : 5.55182 	 
2025-06-12 18:20:17,179 INFO Iter : 72300 	 LR : 0.00017 	 training loss : 5.44264 	 
2025-06-12 18:22:04,872 INFO Iter : 72400 	 LR : 0.00017 	 training loss : 5.04030 	 
2025-06-12 18:23:54,469 INFO Iter : 72500 	 LR : 0.00017 	 training loss : 4.88422 	 
2025-06-12 18:25:47,206 INFO Iter : 72600 	 LR : 0.00017 	 training loss : 4.64444 	 
2025-06-12 18:27:37,008 INFO Iter : 72700 	 LR : 0.00016 	 training loss : 4.86580 	 
2025-06-12 18:29:27,888 INFO Iter : 72800 	 LR : 0.00016 	 training loss : 4.96880 	 
2025-06-12 18:31:20,389 INFO Iter : 72900 	 LR : 0.00016 	 training loss : 5.46280 	 
2025-06-12 18:33:10,723 INFO Iter : 73000 	 LR : 0.00016 	 training loss : 4.87653 	 
2025-06-12 18:33:32,771 INFO WER improved from 0.0738 to 0.0731!!!
2025-06-12 18:33:33,052 INFO Val. loss : 3.983 	 CER : 0.0152 	 WER : 0.0731 	 
2025-06-12 18:36:21,959 INFO Iter : 73100 	 LR : 0.00016 	 training loss : 5.02696 	 
2025-06-12 18:38:11,589 INFO Iter : 73200 	 LR : 0.00016 	 training loss : 5.31038 	 
2025-06-12 18:39:59,674 INFO Iter : 73300 	 LR : 0.00016 	 training loss : 5.35517 	 
2025-06-12 18:41:47,536 INFO Iter : 73400 	 LR : 0.00016 	 training loss : 4.95349 	 
2025-06-12 18:43:36,165 INFO Iter : 73500 	 LR : 0.00016 	 training loss : 4.66042 	 
2025-06-12 18:45:24,663 INFO Iter : 73600 	 LR : 0.00015 	 training loss : 4.99102 	 
2025-06-12 18:47:14,043 INFO Iter : 73700 	 LR : 0.00015 	 training loss : 4.88932 	 
2025-06-12 18:49:03,196 INFO Iter : 73800 	 LR : 0.00015 	 training loss : 4.40464 	 
2025-06-12 18:50:52,121 INFO Iter : 73900 	 LR : 0.00015 	 training loss : 5.01610 	 
2025-06-12 18:52:38,639 INFO Iter : 74000 	 LR : 0.00015 	 training loss : 4.69391 	 
2025-06-12 18:53:00,107 INFO CER improved from 0.0152 to 0.0151!!!
2025-06-12 18:53:00,372 INFO WER improved from 0.0731 to 0.0730!!!
2025-06-12 18:53:00,638 INFO Val. loss : 3.977 	 CER : 0.0151 	 WER : 0.0730 	 
2025-06-12 18:56:18,444 INFO Iter : 74100 	 LR : 0.00015 	 training loss : 5.20065 	 
2025-06-12 18:58:06,820 INFO Iter : 74200 	 LR : 0.00015 	 training loss : 4.95877 	 
2025-06-12 18:59:56,307 INFO Iter : 74300 	 LR : 0.00015 	 training loss : 5.12982 	 
2025-06-12 19:01:46,620 INFO Iter : 74400 	 LR : 0.00014 	 training loss : 4.82652 	 
2025-06-12 19:03:36,269 INFO Iter : 74500 	 LR : 0.00014 	 training loss : 4.62013 	 
2025-06-12 19:05:23,815 INFO Iter : 74600 	 LR : 0.00014 	 training loss : 4.44759 	 
2025-06-12 19:07:13,507 INFO Iter : 74700 	 LR : 0.00014 	 training loss : 4.22963 	 
2025-06-12 19:09:02,875 INFO Iter : 74800 	 LR : 0.00014 	 training loss : 4.53398 	 
2025-06-12 19:10:48,624 INFO Iter : 74900 	 LR : 0.00014 	 training loss : 4.40607 	 
2025-06-12 19:12:40,350 INFO Iter : 75000 	 LR : 0.00014 	 training loss : 5.09025 	 
2025-06-12 19:13:02,814 INFO CER improved from 0.0151 to 0.0150!!!
2025-06-12 19:13:03,110 INFO Val. loss : 3.972 	 CER : 0.0150 	 WER : 0.0731 	 
2025-06-12 19:15:58,368 INFO Iter : 75100 	 LR : 0.00014 	 training loss : 4.67758 	 
2025-06-12 19:17:49,453 INFO Iter : 75200 	 LR : 0.00014 	 training loss : 4.14309 	 
2025-06-12 19:19:41,072 INFO Iter : 75300 	 LR : 0.00013 	 training loss : 4.44661 	 
2025-06-12 19:21:30,695 INFO Iter : 75400 	 LR : 0.00013 	 training loss : 4.28415 	 
2025-06-12 19:23:20,252 INFO Iter : 75500 	 LR : 0.00013 	 training loss : 4.65646 	 
2025-06-12 19:25:10,835 INFO Iter : 75600 	 LR : 0.00013 	 training loss : 4.74948 	 
2025-06-12 19:26:59,972 INFO Iter : 75700 	 LR : 0.00013 	 training loss : 4.71482 	 
2025-06-12 19:28:47,973 INFO Iter : 75800 	 LR : 0.00013 	 training loss : 4.15798 	 
2025-06-12 19:30:37,937 INFO Iter : 75900 	 LR : 0.00013 	 training loss : 4.87650 	 
2025-06-12 19:32:26,706 INFO Iter : 76000 	 LR : 0.00013 	 training loss : 4.29814 	 
2025-06-12 19:32:48,405 INFO CER improved from 0.0150 to 0.0149!!!
2025-06-12 19:32:48,671 INFO WER improved from 0.0730 to 0.0721!!!
2025-06-12 19:32:48,936 INFO Val. loss : 3.975 	 CER : 0.0149 	 WER : 0.0721 	 
2025-06-12 19:36:06,320 INFO Iter : 76100 	 LR : 0.00013 	 training loss : 4.74650 	 
2025-06-12 19:37:57,618 INFO Iter : 76200 	 LR : 0.00013 	 training loss : 4.13808 	 
2025-06-12 19:39:45,969 INFO Iter : 76300 	 LR : 0.00012 	 training loss : 4.89453 	 
2025-06-12 19:41:36,749 INFO Iter : 76400 	 LR : 0.00012 	 training loss : 4.64909 	 
2025-06-12 19:43:27,040 INFO Iter : 76500 	 LR : 0.00012 	 training loss : 3.95081 	 
2025-06-12 19:45:13,621 INFO Iter : 76600 	 LR : 0.00012 	 training loss : 3.98411 	 
2025-06-12 19:47:03,139 INFO Iter : 76700 	 LR : 0.00012 	 training loss : 4.24176 	 
2025-06-12 19:48:51,547 INFO Iter : 76800 	 LR : 0.00012 	 training loss : 4.64228 	 
2025-06-12 19:50:40,690 INFO Iter : 76900 	 LR : 0.00012 	 training loss : 4.45782 	 
2025-06-12 19:52:27,929 INFO Iter : 77000 	 LR : 0.00012 	 training loss : 4.65977 	 
2025-06-12 19:52:49,309 INFO Val. loss : 3.974 	 CER : 0.0150 	 WER : 0.0729 	 
2025-06-12 19:54:43,819 INFO Iter : 77100 	 LR : 0.00012 	 training loss : 4.57169 	 
2025-06-12 19:56:33,136 INFO Iter : 77200 	 LR : 0.00012 	 training loss : 4.35917 	 
2025-06-12 19:58:18,494 INFO Iter : 77300 	 LR : 0.00011 	 training loss : 4.20182 	 
2025-06-12 20:00:06,590 INFO Iter : 77400 	 LR : 0.00011 	 training loss : 3.96441 	 
2025-06-12 20:01:56,524 INFO Iter : 77500 	 LR : 0.00011 	 training loss : 4.33473 	 
2025-06-12 20:03:42,205 INFO Iter : 77600 	 LR : 0.00011 	 training loss : 4.22673 	 
2025-06-12 20:05:30,333 INFO Iter : 77700 	 LR : 0.00011 	 training loss : 3.93213 	 
2025-06-12 20:07:20,698 INFO Iter : 77800 	 LR : 0.00011 	 training loss : 4.10505 	 
2025-06-12 20:09:09,426 INFO Iter : 77900 	 LR : 0.00011 	 training loss : 4.37178 	 
2025-06-12 20:10:58,718 INFO Iter : 78000 	 LR : 0.00011 	 training loss : 4.04476 	 
2025-06-12 20:11:20,613 INFO Val. loss : 3.979 	 CER : 0.0151 	 WER : 0.0731 	 
2025-06-12 20:13:14,005 INFO Iter : 78100 	 LR : 0.00011 	 training loss : 3.99383 	 
2025-06-12 20:15:02,635 INFO Iter : 78200 	 LR : 0.00011 	 training loss : 4.25392 	 
2025-06-12 20:16:50,803 INFO Iter : 78300 	 LR : 0.00010 	 training loss : 4.08788 	 
2025-06-12 20:18:38,769 INFO Iter : 78400 	 LR : 0.00010 	 training loss : 4.34848 	 
2025-06-12 20:20:28,016 INFO Iter : 78500 	 LR : 0.00010 	 training loss : 4.14152 	 
2025-06-12 20:22:15,973 INFO Iter : 78600 	 LR : 0.00010 	 training loss : 4.31928 	 
2025-06-12 20:24:03,231 INFO Iter : 78700 	 LR : 0.00010 	 training loss : 3.87498 	 
2025-06-12 20:25:52,434 INFO Iter : 78800 	 LR : 0.00010 	 training loss : 4.34525 	 
2025-06-12 20:27:41,340 INFO Iter : 78900 	 LR : 0.00010 	 training loss : 4.22800 	 
2025-06-12 20:29:30,653 INFO Iter : 79000 	 LR : 0.00010 	 training loss : 4.50385 	 
2025-06-12 20:29:53,604 INFO Val. loss : 3.985 	 CER : 0.0152 	 WER : 0.0735 	 
2025-06-12 20:31:49,426 INFO Iter : 79100 	 LR : 0.00010 	 training loss : 4.09835 	 
2025-06-12 20:33:37,286 INFO Iter : 79200 	 LR : 0.00010 	 training loss : 4.01432 	 
2025-06-12 20:35:24,595 INFO Iter : 79300 	 LR : 0.00009 	 training loss : 4.17683 	 
2025-06-12 20:37:14,947 INFO Iter : 79400 	 LR : 0.00009 	 training loss : 4.01787 	 
2025-06-12 20:39:02,220 INFO Iter : 79500 	 LR : 0.00009 	 training loss : 4.01306 	 
2025-06-12 20:40:50,977 INFO Iter : 79600 	 LR : 0.00009 	 training loss : 4.39957 	 
2025-06-12 20:42:41,464 INFO Iter : 79700 	 LR : 0.00009 	 training loss : 4.39931 	 
2025-06-12 20:44:30,775 INFO Iter : 79800 	 LR : 0.00009 	 training loss : 4.21508 	 
2025-06-12 20:46:18,381 INFO Iter : 79900 	 LR : 0.00009 	 training loss : 4.08348 	 
2025-06-12 20:48:07,795 INFO Iter : 80000 	 LR : 0.00009 	 training loss : 4.40612 	 
2025-06-12 20:48:29,760 INFO WER improved from 0.0721 to 0.0717!!!
2025-06-12 20:48:30,072 INFO Val. loss : 3.974 	 CER : 0.0150 	 WER : 0.0717 	 
2025-06-12 20:51:14,096 INFO Iter : 80100 	 LR : 0.00009 	 training loss : 3.75300 	 
2025-06-12 20:53:03,938 INFO Iter : 80200 	 LR : 0.00009 	 training loss : 3.71279 	 
2025-06-12 20:54:53,133 INFO Iter : 80300 	 LR : 0.00009 	 training loss : 3.94450 	 
2025-06-12 20:56:41,663 INFO Iter : 80400 	 LR : 0.00008 	 training loss : 4.22630 	 
2025-06-12 20:58:30,032 INFO Iter : 80500 	 LR : 0.00008 	 training loss : 3.94350 	 
2025-06-12 21:00:18,896 INFO Iter : 80600 	 LR : 0.00008 	 training loss : 3.43145 	 
2025-06-12 21:02:09,280 INFO Iter : 80700 	 LR : 0.00008 	 training loss : 4.40527 	 
2025-06-12 21:03:56,620 INFO Iter : 80800 	 LR : 0.00008 	 training loss : 3.88885 	 
2025-06-12 21:05:45,120 INFO Iter : 80900 	 LR : 0.00008 	 training loss : 4.35679 	 
2025-06-12 21:07:34,711 INFO Iter : 81000 	 LR : 0.00008 	 training loss : 3.98667 	 
2025-06-12 21:07:55,622 INFO Val. loss : 3.972 	 CER : 0.0152 	 WER : 0.0729 	 
2025-06-12 21:09:49,968 INFO Iter : 81100 	 LR : 0.00008 	 training loss : 4.11609 	 
2025-06-12 21:11:38,592 INFO Iter : 81200 	 LR : 0.00008 	 training loss : 3.71952 	 
2025-06-12 21:13:29,061 INFO Iter : 81300 	 LR : 0.00008 	 training loss : 3.75074 	 
2025-06-12 21:15:17,765 INFO Iter : 81400 	 LR : 0.00008 	 training loss : 3.99975 	 
2025-06-12 21:17:05,753 INFO Iter : 81500 	 LR : 0.00008 	 training loss : 4.08197 	 
2025-06-12 21:18:55,220 INFO Iter : 81600 	 LR : 0.00007 	 training loss : 3.54156 	 
2025-06-12 21:20:44,181 INFO Iter : 81700 	 LR : 0.00007 	 training loss : 4.04714 	 
2025-06-12 21:22:31,134 INFO Iter : 81800 	 LR : 0.00007 	 training loss : 3.40002 	 
2025-06-12 21:24:20,743 INFO Iter : 81900 	 LR : 0.00007 	 training loss : 3.69660 	 
2025-06-12 21:26:10,088 INFO Iter : 82000 	 LR : 0.00007 	 training loss : 3.57447 	 
2025-06-12 21:26:31,732 INFO Val. loss : 3.964 	 CER : 0.0151 	 WER : 0.0722 	 
2025-06-12 21:28:26,649 INFO Iter : 82100 	 LR : 0.00007 	 training loss : 3.95210 	 
2025-06-12 21:30:17,284 INFO Iter : 82200 	 LR : 0.00007 	 training loss : 4.29147 	 
2025-06-12 21:32:09,005 INFO Iter : 82300 	 LR : 0.00007 	 training loss : 3.48187 	 
2025-06-12 21:33:59,132 INFO Iter : 82400 	 LR : 0.00007 	 training loss : 3.73672 	 
2025-06-12 21:35:47,539 INFO Iter : 82500 	 LR : 0.00007 	 training loss : 3.48702 	 
2025-06-12 21:37:36,546 INFO Iter : 82600 	 LR : 0.00007 	 training loss : 3.17611 	 
2025-06-12 21:39:24,283 INFO Iter : 82700 	 LR : 0.00007 	 training loss : 3.44839 	 
2025-06-12 21:41:13,434 INFO Iter : 82800 	 LR : 0.00006 	 training loss : 3.35881 	 
2025-06-12 21:43:02,826 INFO Iter : 82900 	 LR : 0.00006 	 training loss : 3.72746 	 
2025-06-12 21:44:50,157 INFO Iter : 83000 	 LR : 0.00006 	 training loss : 3.76072 	 
2025-06-12 21:45:10,982 INFO Val. loss : 3.975 	 CER : 0.0151 	 WER : 0.0726 	 
2025-06-12 21:47:11,371 INFO Iter : 83100 	 LR : 0.00006 	 training loss : 3.79326 	 
2025-06-12 21:49:02,521 INFO Iter : 83200 	 LR : 0.00006 	 training loss : 3.43664 	 
2025-06-12 21:50:53,177 INFO Iter : 83300 	 LR : 0.00006 	 training loss : 3.81854 	 
2025-06-12 21:52:41,547 INFO Iter : 83400 	 LR : 0.00006 	 training loss : 3.65945 	 
2025-06-12 21:54:32,188 INFO Iter : 83500 	 LR : 0.00006 	 training loss : 3.27246 	 
2025-06-12 21:56:21,826 INFO Iter : 83600 	 LR : 0.00006 	 training loss : 3.66921 	 
2025-06-12 21:58:09,426 INFO Iter : 83700 	 LR : 0.00006 	 training loss : 3.47305 	 
2025-06-12 21:59:59,178 INFO Iter : 83800 	 LR : 0.00006 	 training loss : 3.89060 	 
2025-06-12 22:01:50,250 INFO Iter : 83900 	 LR : 0.00006 	 training loss : 3.67863 	 
2025-06-12 22:03:36,875 INFO Iter : 84000 	 LR : 0.00006 	 training loss : 3.88254 	 
2025-06-12 22:03:58,462 INFO CER improved from 0.0149 to 0.0149!!!
2025-06-12 22:03:58,743 INFO Val. loss : 3.989 	 CER : 0.0149 	 WER : 0.0718 	 
2025-06-12 22:06:47,523 INFO Iter : 84100 	 LR : 0.00005 	 training loss : 3.22088 	 
2025-06-12 22:08:37,219 INFO Iter : 84200 	 LR : 0.00005 	 training loss : 3.49907 	 
2025-06-12 22:10:25,133 INFO Iter : 84300 	 LR : 0.00005 	 training loss : 3.04949 	 
2025-06-12 22:12:13,239 INFO Iter : 84400 	 LR : 0.00005 	 training loss : 3.54653 	 
2025-06-12 22:14:03,018 INFO Iter : 84500 	 LR : 0.00005 	 training loss : 3.38145 	 
2025-06-12 22:15:49,972 INFO Iter : 84600 	 LR : 0.00005 	 training loss : 3.06361 	 
2025-06-12 22:17:38,644 INFO Iter : 84700 	 LR : 0.00005 	 training loss : 3.38741 	 
2025-06-12 22:19:29,020 INFO Iter : 84800 	 LR : 0.00005 	 training loss : 3.74362 	 
2025-06-12 22:21:17,653 INFO Iter : 84900 	 LR : 0.00005 	 training loss : 3.51125 	 
2025-06-12 22:23:06,080 INFO Iter : 85000 	 LR : 0.00005 	 training loss : 4.22849 	 
2025-06-12 22:23:29,115 INFO Val. loss : 4.016 	 CER : 0.0153 	 WER : 0.0729 	 
2025-06-12 22:25:23,979 INFO Iter : 85100 	 LR : 0.00005 	 training loss : 3.51202 	 
2025-06-12 22:27:13,938 INFO Iter : 85200 	 LR : 0.00005 	 training loss : 3.37850 	 
2025-06-12 22:29:04,502 INFO Iter : 85300 	 LR : 0.00005 	 training loss : 3.18458 	 
2025-06-12 22:30:55,621 INFO Iter : 85400 	 LR : 0.00005 	 training loss : 3.24056 	 
2025-06-12 22:32:44,993 INFO Iter : 85500 	 LR : 0.00005 	 training loss : 3.07433 	 
2025-06-12 22:34:31,117 INFO Iter : 85600 	 LR : 0.00004 	 training loss : 3.14057 	 
2025-06-12 22:36:20,389 INFO Iter : 85700 	 LR : 0.00004 	 training loss : 3.03539 	 
2025-06-12 22:38:10,045 INFO Iter : 85800 	 LR : 0.00004 	 training loss : 3.47608 	 
2025-06-12 22:39:58,633 INFO Iter : 85900 	 LR : 0.00004 	 training loss : 3.51160 	 
2025-06-12 22:41:45,179 INFO Iter : 86000 	 LR : 0.00004 	 training loss : 3.49003 	 
2025-06-12 22:42:07,278 INFO Val. loss : 4.016 	 CER : 0.0153 	 WER : 0.0729 	 
2025-06-12 22:44:04,667 INFO Iter : 86100 	 LR : 0.00004 	 training loss : 2.98138 	 
2025-06-12 22:45:50,415 INFO Iter : 86200 	 LR : 0.00004 	 training loss : 3.24238 	 
2025-06-12 22:47:40,045 INFO Iter : 86300 	 LR : 0.00004 	 training loss : 3.07013 	 
2025-06-12 22:49:31,898 INFO Iter : 86400 	 LR : 0.00004 	 training loss : 3.49984 	 
2025-06-12 22:51:20,821 INFO Iter : 86500 	 LR : 0.00004 	 training loss : 3.78969 	 
2025-06-12 22:53:09,123 INFO Iter : 86600 	 LR : 0.00004 	 training loss : 3.02550 	 
2025-06-12 22:54:58,636 INFO Iter : 86700 	 LR : 0.00004 	 training loss : 3.37448 	 
2025-06-12 22:56:47,788 INFO Iter : 86800 	 LR : 0.00004 	 training loss : 3.00829 	 
2025-06-12 22:58:36,615 INFO Iter : 86900 	 LR : 0.00004 	 training loss : 3.15036 	 
2025-06-12 23:00:25,377 INFO Iter : 87000 	 LR : 0.00004 	 training loss : 3.71135 	 
2025-06-12 23:00:47,536 INFO WER improved from 0.0717 to 0.0714!!!
2025-06-12 23:00:47,849 INFO Val. loss : 4.011 	 CER : 0.0150 	 WER : 0.0714 	 
2025-06-12 23:03:35,863 INFO Iter : 87100 	 LR : 0.00004 	 training loss : 3.17228 	 
2025-06-12 23:05:24,160 INFO Iter : 87200 	 LR : 0.00003 	 training loss : 3.06569 	 
2025-06-12 23:07:14,708 INFO Iter : 87300 	 LR : 0.00003 	 training loss : 3.16247 	 
2025-06-12 23:09:04,259 INFO Iter : 87400 	 LR : 0.00003 	 training loss : 3.25096 	 
2025-06-12 23:10:52,185 INFO Iter : 87500 	 LR : 0.00003 	 training loss : 3.37082 	 
2025-06-12 23:12:40,135 INFO Iter : 87600 	 LR : 0.00003 	 training loss : 3.02495 	 
2025-06-12 23:14:29,299 INFO Iter : 87700 	 LR : 0.00003 	 training loss : 3.43643 	 
2025-06-12 23:16:16,911 INFO Iter : 87800 	 LR : 0.00003 	 training loss : 3.08403 	 
2025-06-12 23:18:05,788 INFO Iter : 87900 	 LR : 0.00003 	 training loss : 2.87631 	 
2025-06-12 23:19:56,766 INFO Iter : 88000 	 LR : 0.00003 	 training loss : 2.97956 	 
2025-06-12 23:20:17,964 INFO Val. loss : 4.029 	 CER : 0.0151 	 WER : 0.0719 	 
2025-06-12 23:22:11,132 INFO Iter : 88100 	 LR : 0.00003 	 training loss : 3.25888 	 
2025-06-12 23:24:01,170 INFO Iter : 88200 	 LR : 0.00003 	 training loss : 3.07542 	 
2025-06-12 23:25:51,531 INFO Iter : 88300 	 LR : 0.00003 	 training loss : 3.05377 	 
2025-06-12 23:27:37,781 INFO Iter : 88400 	 LR : 0.00003 	 training loss : 3.18689 	 
2025-06-12 23:29:27,964 INFO Iter : 88500 	 LR : 0.00003 	 training loss : 3.06616 	 
2025-06-12 23:31:18,242 INFO Iter : 88600 	 LR : 0.00003 	 training loss : 3.03016 	 
2025-06-12 23:33:07,202 INFO Iter : 88700 	 LR : 0.00003 	 training loss : 3.05894 	 
2025-06-12 23:34:55,139 INFO Iter : 88800 	 LR : 0.00003 	 training loss : 2.78763 	 
2025-06-12 23:36:43,846 INFO Iter : 88900 	 LR : 0.00003 	 training loss : 2.79364 	 
2025-06-12 23:38:34,159 INFO Iter : 89000 	 LR : 0.00003 	 training loss : 2.96976 	 
2025-06-12 23:38:55,078 INFO Val. loss : 4.039 	 CER : 0.0150 	 WER : 0.0725 	 
2025-06-12 23:40:49,559 INFO Iter : 89100 	 LR : 0.00002 	 training loss : 3.14397 	 
2025-06-12 23:42:36,831 INFO Iter : 89200 	 LR : 0.00002 	 training loss : 3.20842 	 
2025-06-12 23:44:26,810 INFO Iter : 89300 	 LR : 0.00002 	 training loss : 2.88090 	 
2025-06-12 23:46:15,603 INFO Iter : 89400 	 LR : 0.00002 	 training loss : 3.20047 	 
2025-06-12 23:48:05,148 INFO Iter : 89500 	 LR : 0.00002 	 training loss : 3.45462 	 
2025-06-12 23:49:55,942 INFO Iter : 89600 	 LR : 0.00002 	 training loss : 2.96606 	 
2025-06-12 23:51:42,886 INFO Iter : 89700 	 LR : 0.00002 	 training loss : 3.22448 	 
2025-06-12 23:53:30,484 INFO Iter : 89800 	 LR : 0.00002 	 training loss : 3.18720 	 
2025-06-12 23:55:20,120 INFO Iter : 89900 	 LR : 0.00002 	 training loss : 3.42162 	 
2025-06-12 23:57:08,836 INFO Iter : 90000 	 LR : 0.00002 	 training loss : 3.07083 	 
2025-06-12 23:57:31,133 INFO Val. loss : 4.041 	 CER : 0.0154 	 WER : 0.0742 	 
2025-06-12 23:59:25,083 INFO Iter : 90100 	 LR : 0.00002 	 training loss : 2.88471 	 
2025-06-13 00:01:13,827 INFO Iter : 90200 	 LR : 0.00002 	 training loss : 2.99705 	 
2025-06-13 00:03:03,543 INFO Iter : 90300 	 LR : 0.00002 	 training loss : 3.07420 	 
2025-06-13 00:04:51,211 INFO Iter : 90400 	 LR : 0.00002 	 training loss : 3.10428 	 
2025-06-13 00:06:41,490 INFO Iter : 90500 	 LR : 0.00002 	 training loss : 3.05036 	 
2025-06-13 00:08:31,540 INFO Iter : 90600 	 LR : 0.00002 	 training loss : 2.58677 	 
2025-06-13 00:10:19,763 INFO Iter : 90700 	 LR : 0.00002 	 training loss : 2.63447 	 
2025-06-13 00:12:08,540 INFO Iter : 90800 	 LR : 0.00002 	 training loss : 3.00975 	 
2025-06-13 00:13:56,773 INFO Iter : 90900 	 LR : 0.00002 	 training loss : 2.92222 	 
2025-06-13 00:15:43,309 INFO Iter : 91000 	 LR : 0.00002 	 training loss : 2.63618 	 
2025-06-13 00:16:05,206 INFO Val. loss : 4.066 	 CER : 0.0154 	 WER : 0.0730 	 
2025-06-13 00:17:59,983 INFO Iter : 91100 	 LR : 0.00002 	 training loss : 2.76302 	 
2025-06-13 00:19:48,606 INFO Iter : 91200 	 LR : 0.00002 	 training loss : 2.89958 	 
2025-06-13 00:21:35,901 INFO Iter : 91300 	 LR : 0.00001 	 training loss : 3.31125 	 
2025-06-13 00:23:23,165 INFO Iter : 91400 	 LR : 0.00001 	 training loss : 2.70277 	 
2025-06-13 00:25:13,524 INFO Iter : 91500 	 LR : 0.00001 	 training loss : 2.79938 	 
2025-06-13 00:27:00,407 INFO Iter : 91600 	 LR : 0.00001 	 training loss : 2.81010 	 
2025-06-13 00:28:49,067 INFO Iter : 91700 	 LR : 0.00001 	 training loss : 2.69821 	 
2025-06-13 00:30:37,123 INFO Iter : 91800 	 LR : 0.00001 	 training loss : 3.22843 	 
2025-06-13 00:32:26,679 INFO Iter : 91900 	 LR : 0.00001 	 training loss : 2.98365 	 
2025-06-13 00:34:13,694 INFO Iter : 92000 	 LR : 0.00001 	 training loss : 2.60254 	 
2025-06-13 00:34:36,184 INFO Val. loss : 4.080 	 CER : 0.0154 	 WER : 0.0735 	 
2025-06-13 00:36:32,435 INFO Iter : 92100 	 LR : 0.00001 	 training loss : 2.91811 	 
2025-06-13 00:38:22,521 INFO Iter : 92200 	 LR : 0.00001 	 training loss : 3.01030 	 
2025-06-13 00:40:09,333 INFO Iter : 92300 	 LR : 0.00001 	 training loss : 2.81183 	 
2025-06-13 00:41:57,232 INFO Iter : 92400 	 LR : 0.00001 	 training loss : 2.74880 	 
2025-06-13 00:43:46,416 INFO Iter : 92500 	 LR : 0.00001 	 training loss : 2.80426 	 
2025-06-13 00:45:35,563 INFO Iter : 92600 	 LR : 0.00001 	 training loss : 2.86596 	 
2025-06-13 00:47:23,447 INFO Iter : 92700 	 LR : 0.00001 	 training loss : 2.45346 	 
2025-06-13 00:49:13,972 INFO Iter : 92800 	 LR : 0.00001 	 training loss : 2.46982 	 
2025-06-13 00:51:02,217 INFO Iter : 92900 	 LR : 0.00001 	 training loss : 2.84710 	 
2025-06-13 00:52:50,466 INFO Iter : 93000 	 LR : 0.00001 	 training loss : 2.49588 	 
2025-06-13 00:53:11,306 INFO Val. loss : 4.091 	 CER : 0.0155 	 WER : 0.0745 	 
2025-06-13 00:55:06,749 INFO Iter : 93100 	 LR : 0.00001 	 training loss : 2.43183 	 
2025-06-13 00:56:54,544 INFO Iter : 93200 	 LR : 0.00001 	 training loss : 2.79652 	 
2025-06-13 00:58:39,541 INFO Iter : 93300 	 LR : 0.00001 	 training loss : 2.76661 	 
2025-06-13 01:00:28,734 INFO Iter : 93400 	 LR : 0.00001 	 training loss : 2.66575 	 
2025-06-13 01:02:18,649 INFO Iter : 93500 	 LR : 0.00001 	 training loss : 2.60958 	 
2025-06-13 01:04:03,588 INFO Iter : 93600 	 LR : 0.00001 	 training loss : 2.79261 	 
2025-06-13 01:05:52,360 INFO Iter : 93700 	 LR : 0.00001 	 training loss : 2.91211 	 
2025-06-13 01:07:43,265 INFO Iter : 93800 	 LR : 0.00001 	 training loss : 2.21791 	 
2025-06-13 01:09:30,860 INFO Iter : 93900 	 LR : 0.00001 	 training loss : 2.66924 	 
2025-06-13 01:11:19,111 INFO Iter : 94000 	 LR : 0.00001 	 training loss : 2.79136 	 
2025-06-13 01:11:41,862 INFO Val. loss : 4.109 	 CER : 0.0157 	 WER : 0.0745 	 
2025-06-13 01:13:37,293 INFO Iter : 94100 	 LR : 0.00001 	 training loss : 2.61973 	 
2025-06-13 01:15:25,830 INFO Iter : 94200 	 LR : 0.00001 	 training loss : 2.65360 	 
2025-06-13 01:17:15,292 INFO Iter : 94300 	 LR : 0.00001 	 training loss : 2.64139 	 
2025-06-13 01:19:04,964 INFO Iter : 94400 	 LR : 0.00001 	 training loss : 2.32369 	 
2025-06-13 01:20:55,275 INFO Iter : 94500 	 LR : 0.00001 	 training loss : 2.83277 	 
2025-06-13 01:22:43,765 INFO Iter : 94600 	 LR : 0.00000 	 training loss : 2.52670 	 
2025-06-13 01:24:33,324 INFO Iter : 94700 	 LR : 0.00000 	 training loss : 2.42307 	 
2025-06-13 01:26:22,978 INFO Iter : 94800 	 LR : 0.00000 	 training loss : 2.51051 	 
2025-06-13 01:28:09,269 INFO Iter : 94900 	 LR : 0.00000 	 training loss : 2.50594 	 
2025-06-13 01:29:57,314 INFO Iter : 95000 	 LR : 0.00000 	 training loss : 2.47097 	 
2025-06-13 01:30:19,165 INFO Val. loss : 4.135 	 CER : 0.0156 	 WER : 0.0739 	 
2025-06-13 01:32:17,206 INFO Iter : 95100 	 LR : 0.00000 	 training loss : 2.99651 	 
2025-06-13 01:34:05,190 INFO Iter : 95200 	 LR : 0.00000 	 training loss : 2.55610 	 
2025-06-13 01:35:52,473 INFO Iter : 95300 	 LR : 0.00000 	 training loss : 2.57215 	 
2025-06-13 01:37:41,022 INFO Iter : 95400 	 LR : 0.00000 	 training loss : 2.85081 	 
2025-06-13 01:39:28,709 INFO Iter : 95500 	 LR : 0.00000 	 training loss : 2.65636 	 
2025-06-13 01:41:17,746 INFO Iter : 95600 	 LR : 0.00000 	 training loss : 2.55688 	 
2025-06-13 01:43:06,837 INFO Iter : 95700 	 LR : 0.00000 	 training loss : 3.02994 	 
2025-06-13 01:44:58,279 INFO Iter : 95800 	 LR : 0.00000 	 training loss : 2.89497 	 
2025-06-13 01:46:44,285 INFO Iter : 95900 	 LR : 0.00000 	 training loss : 2.19759 	 
2025-06-13 01:48:34,147 INFO Iter : 96000 	 LR : 0.00000 	 training loss : 2.58570 	 
2025-06-13 01:48:55,996 INFO Val. loss : 4.135 	 CER : 0.0156 	 WER : 0.0734 	 
2025-06-13 01:50:49,164 INFO Iter : 96100 	 LR : 0.00000 	 training loss : 2.36072 	 
2025-06-13 01:52:36,961 INFO Iter : 96200 	 LR : 0.00000 	 training loss : 2.51555 	 
2025-06-13 01:54:25,667 INFO Iter : 96300 	 LR : 0.00000 	 training loss : 2.68991 	 
2025-06-13 01:56:17,094 INFO Iter : 96400 	 LR : 0.00000 	 training loss : 2.61191 	 
2025-06-13 01:58:04,604 INFO Iter : 96500 	 LR : 0.00000 	 training loss : 2.58395 	 
2025-06-13 01:59:52,720 INFO Iter : 96600 	 LR : 0.00000 	 training loss : 2.62787 	 
2025-06-13 02:01:44,135 INFO Iter : 96700 	 LR : 0.00000 	 training loss : 2.68381 	 
2025-06-13 02:03:30,741 INFO Iter : 96800 	 LR : 0.00000 	 training loss : 2.40259 	 
2025-06-13 02:05:17,678 INFO Iter : 96900 	 LR : 0.00000 	 training loss : 2.58419 	 
2025-06-13 02:07:06,816 INFO Iter : 97000 	 LR : 0.00000 	 training loss : 2.80583 	 
2025-06-13 02:07:28,242 INFO Val. loss : 4.138 	 CER : 0.0156 	 WER : 0.0734 	 
2025-06-13 02:09:23,171 INFO Iter : 97100 	 LR : 0.00000 	 training loss : 2.40041 	 
2025-06-13 02:11:13,424 INFO Iter : 97200 	 LR : 0.00000 	 training loss : 3.03624 	 
2025-06-13 02:13:05,505 INFO Iter : 97300 	 LR : 0.00000 	 training loss : 2.51959 	 
2025-06-13 02:14:54,379 INFO Iter : 97400 	 LR : 0.00000 	 training loss : 2.72202 	 
2025-06-13 02:16:42,385 INFO Iter : 97500 	 LR : 0.00000 	 training loss : 2.88635 	 
2025-06-13 02:18:32,239 INFO Iter : 97600 	 LR : 0.00000 	 training loss : 2.55041 	 
2025-06-13 02:20:23,269 INFO Iter : 97700 	 LR : 0.00000 	 training loss : 2.67446 	 
2025-06-13 02:22:11,711 INFO Iter : 97800 	 LR : 0.00000 	 training loss : 2.68642 	 
2025-06-13 02:24:02,076 INFO Iter : 97900 	 LR : 0.00000 	 training loss : 2.21764 	 
2025-06-13 02:25:50,891 INFO Iter : 98000 	 LR : 0.00000 	 training loss : 2.54237 	 
2025-06-13 02:26:11,555 INFO Val. loss : 4.140 	 CER : 0.0157 	 WER : 0.0746 	 
